{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# MAIN IMPORTS \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from torchviz import make_dot\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torchvision.transforms as T\n",
    "from skimage import transform as sktf\n",
    "from skimage.util import random_noise\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "import gc\n",
    "from torch.optim import lr_scheduler\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_gpu_memory(model=None, data_loaders=None):\n",
    "    \n",
    "    if model is not None:\n",
    "        model.cpu()\n",
    "        del model\n",
    "    \n",
    "    \n",
    "    if data_loaders is not None:\n",
    "        for loader in data_loaders:\n",
    "            del loader  \n",
    "    \n",
    "    #  garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tensor_as_image(tensor, channel_num, channel_index, height_index, width_index):\n",
    "    # Move the tensor to CPU and convert it to a NumPy array\n",
    "    tensor_np = tensor.cpu().numpy()\n",
    "    if channel_index == 1:\n",
    "        tensor_np = tensor_np.squeeze(0)\n",
    "\n",
    "        channel_index -=1\n",
    "        height_index-=1\n",
    "        width_index-=1\n",
    "        \n",
    "    # Handle single-channel (grayscale) image\n",
    "    if channel_num == 1:\n",
    "        image_np = tensor_np.squeeze(channel_index)  # Remove the channel dimension\n",
    "        plt.imshow(image_np, cmap=\"gray\")\n",
    "        plt.title(\"Single-channel image\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Handle two-channel image (display channels separately)\n",
    "    elif channel_num == 2:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))  # Create 1 row, 2 columns\n",
    "        for i in range(2):\n",
    "            channel_image = tensor_np[i]  # Select each channel (e.g., 0 and 1)\n",
    "            axes[i].imshow(channel_image, cmap=\"gray\")\n",
    "            axes[i].set_title(f\"Channel {i}\")\n",
    "            # print(f\"Max value in channel {i}:\", np.max(channel_image))\n",
    "            # print(f\"Min value in channel {i}:\", np.min(channel_image))\n",
    "        plt.show()\n",
    "    \n",
    "    # Handle three-channel image (RGB)\n",
    "    elif channel_num == 3:\n",
    "        print(tensor_np.shape)\n",
    "        # Transpose from (channels, height, width) to (height, width, channels)\n",
    "        image_np = np.transpose(tensor_np, (height_index, width_index, channel_index))\n",
    "        plt.imshow(image_np)\n",
    "        plt.title(\"Three-channel image (RGB)\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PuzzleDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None, num_transforms=0,include_inverse_mask=True):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.num_transforms = num_transforms\n",
    "        self.include_inverse_mask=include_inverse_mask\n",
    "        images = sorted(os.listdir(img_dir))\n",
    "        masks = sorted(os.listdir(mask_dir))\n",
    "        self.data = []\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            img_path = os.path.join(self.img_dir, images[i])\n",
    "            mask_path = os.path.join(self.mask_dir, masks[i])\n",
    "\n",
    "          \n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (512, 512))\n",
    "            image = image.astype(np.float32)/255.0\n",
    "            # image = Image.fromarray(image)  \n",
    "\n",
    "            \n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.resize(mask, (512,512))\n",
    "            mask = (mask > 0.5).astype(np.float32) \n",
    "            # mask = Image.fromarray(mask)  #   PIL image needed for transforms\n",
    "\n",
    "            # store the original image and mask\n",
    "            self.append_image_mask(image, mask)\n",
    "\n",
    "            # do transformations \n",
    "            for _ in range(self.num_transforms):\n",
    "                transformed_image, transformed_mask = self.apply_transform(image, mask)\n",
    "                self.append_image_mask(transformed_image, transformed_mask)\n",
    "\n",
    "    def apply_transform(self, image, mask):\n",
    "        \"\"\"Apply deterministic transformations to both image and mask\n",
    "        This is imortant since using the torchvision.transforms was givin a random transform\n",
    "        for both image and mask -> they didn't match up\"\"\"\n",
    "        if self.transform:\n",
    "            \n",
    "            if random.random() > 0.5:\n",
    "                image = np.fliplr(image)\n",
    "                mask = np.fliplr(mask)\n",
    "\n",
    "           \n",
    "            if random.random() > 0.5:\n",
    "                image = np.flipud(image)\n",
    "                mask = np.flipud(mask)\n",
    "\n",
    "            # Apply rotation deterministically\n",
    "            angle = np.random.uniform(-30, 30)\n",
    "            image = sktf.rotate(image, angle, mode=\"edge\" , preserve_range=True)\n",
    "            mask = sktf.rotate(mask, angle, mode=\"edge\" , preserve_range=True)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def append_image_mask(self, image, mask):\n",
    "        \"\"\"need to store them as tensors.\"\"\"\n",
    "        image = torch.tensor(image.transpose((2, 0, 1)), dtype=torch.float32) # (C, H, W)\n",
    "        mask = torch.tensor(mask[None, ...], dtype=torch.float32)   # (1, H, W)\n",
    "\n",
    "       \n",
    "        if(self.include_inverse_mask):\n",
    "            inverse_mask = 1 - mask\n",
    "            combined_mask = torch.cat([inverse_mask, mask], dim=0)  # Combined (2, H, W)\n",
    "\n",
    "        \n",
    "            self.data.append((image, combined_mask))\n",
    "        else:\n",
    "            self.data.append((image,mask))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PuzzleDataset(\n",
    "    img_dir=\"./images-1024x768/train/\",\n",
    "    mask_dir=\"./masks-1024x768/train/\", \n",
    "    transform=True,\n",
    "    num_transforms=3  \n",
    ")\n",
    "\n",
    "val_dataset = PuzzleDataset(\n",
    "    img_dir=\"./images-1024x768/val/\",\n",
    "    mask_dir=\"./masks-1024x768/val/\", \n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = PuzzleDataset(img_dir = \"./images-1024x768/test/\",\n",
    "                            mask_dir = \"./masks-1024x768/test/\")\n",
    "\n",
    "train_dataloader =DataLoader(train_dataset,batch_size =2, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size =1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep lab v3\n",
    "EPOCHS = 30\n",
    "T_MAX = EPOCHS * len(train_dataloader)\n",
    "OUT_CLASSES = 2\n",
    "\n",
    "class DeepV_plus(pl.LightningModule):\n",
    "    def __init__(self, arch, encoder_name, in_channels, out_classes, pretrained=\"imagenet\", **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = smp.create_model(\n",
    "            arch,\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=pretrained,\n",
    "            in_channels=in_channels,\n",
    "            classes=out_classes,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.encoder_name = encoder_name\n",
    "        self.arch_name = arch\n",
    "        self.in_channels = in_channels\n",
    "        self.out_classes = out_classes\n",
    "        # preprocessing parameteres for image\n",
    "        print(pretrained)\n",
    "        params = smp.encoders.get_preprocessing_params(encoder_name,pretrained)\n",
    "        self.register_buffer(\"std\", torch.tensor(params[\"std\"]).view(1, 3, 1, 1))\n",
    "        self.register_buffer(\"mean\", torch.tensor(params[\"mean\"]).view(1, 3, 1, 1))\n",
    "\n",
    "        # for image segmentation dice loss could be the best first choice\n",
    "        self.loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "\n",
    "        # initialize step metics\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "    def forward(self, image):\n",
    "        # normalize image here\n",
    "        image = (image - self.mean) / self.std\n",
    "        mask = self.model(image)\n",
    "        return mask\n",
    "\n",
    "    def shared_step(self, batch, stage):\n",
    "        image = batch[0]\n",
    "\n",
    "        # Shape of the image should be (batch_size, num_channels, height, width)\n",
    "        # if you work with grayscale images, expand channels dim to have [batch_size, 1, height, width]\n",
    "        assert image.ndim == 4\n",
    "\n",
    "        # Check that image dimensions are divisible by 32,\n",
    "        # encoder and decoder connected by `skip connections` and usually encoder have 5 stages of\n",
    "        # downsampling by factor 2 (2 ^ 5 = 32); e.g. if we have image with shape 65x65 we will have\n",
    "        # following shapes of features in encoder and decoder: 84, 42, 21, 10, 5 -> 5, 10, 20, 40, 80\n",
    "        # and we will get an error trying to concat these features\n",
    "        h, w = image.shape[2:]\n",
    "        assert h % 32 == 0 and w % 32 == 0\n",
    "\n",
    "        mask = batch[1]\n",
    "        assert mask.ndim == 4\n",
    "\n",
    "        # Check that mask values in between 0 and 1, NOT 0 and 255 for binary segmentation\n",
    "        assert mask.max() <= 1.0 and mask.min() >= 0\n",
    "\n",
    "        logits_mask = self.forward(image)\n",
    "\n",
    "        # Predicted mask contains logits, and loss_fn param `from_logits` is set to True\n",
    "        loss = self.loss_fn(logits_mask, mask)\n",
    "\n",
    "        # Lets compute metrics for some threshold\n",
    "        # first convert mask values to probabilities, then\n",
    "        # apply thresholding\n",
    "        prob_mask = logits_mask.sigmoid()\n",
    "        pred_mask = (prob_mask > 0.5).float()\n",
    "        # We will compute IoU metric by two ways\n",
    "        #   1. dataset-wise\n",
    "        #   2. image-wise\n",
    "        # but for now we just compute true positive, false positive, false negative and\n",
    "        # true negative 'pixels' for each image and class\n",
    "        # these values will be aggregated in the end of an epoch\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(\n",
    "            pred_mask.long(), mask.long(), mode=\"binary\"\n",
    "        )\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"tp\": tp,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn,\n",
    "            \"tn\": tn,\n",
    "        }\n",
    "\n",
    "    def shared_epoch_end(self, outputs, stage):\n",
    "        \n",
    "        losses = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(f\"val_loss\", losses, prog_bar=True)\n",
    "        # aggregate step metics\n",
    "        tp = torch.cat([x[\"tp\"] for x in outputs])\n",
    "        fp = torch.cat([x[\"fp\"] for x in outputs])\n",
    "        fn = torch.cat([x[\"fn\"] for x in outputs])\n",
    "        tn = torch.cat([x[\"tn\"] for x in outputs])\n",
    "\n",
    "        #F1 score\n",
    "        precision = tp.sum() / (tp.sum() + fp.sum() + 1e-6)  # Add small value to avoid division by zero\n",
    "        recall = tp.sum() / (tp.sum() + fn.sum() + 1e-6)     # Add small value to avoid division by zero\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall + 1e-6)    \n",
    "        # per image IoU means that we first calculate IoU score for each image\n",
    "        # and then compute mean over these scores\n",
    "        per_image_iou = smp.metrics.iou_score(\n",
    "            tp, fp, fn, tn, reduction=\"micro-imagewise\"\n",
    "        )\n",
    "\n",
    "        # dataset IoU means that we aggregate intersection and union over whole dataset\n",
    "        # and then compute IoU score. The difference between dataset_iou and per_image_iou scores\n",
    "        # in this particular case will not be much, however for dataset\n",
    "        # with \"empty\" images (images without target class) a large gap could be observed.\n",
    "        # Empty images influence a lot on per_image_iou and much less on dataset_iou.\n",
    "        dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        metrics = {\n",
    "            f\"{stage}_per_image_iou\": per_image_iou,\n",
    "            f\"{stage}_dataset_iou\": dataset_iou,\n",
    "            f\"{stage}_f1_score\": f1_score  # Log the F1 score\n",
    "        }\n",
    "\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        train_loss_info = self.shared_step(batch, \"train\")\n",
    "        # append the metics of each step to the\n",
    "        self.training_step_outputs.append(train_loss_info)\n",
    "        return train_loss_info\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.shared_epoch_end(self.training_step_outputs, \"train\")\n",
    "        # empty set output list\n",
    "        self.training_step_outputs.clear()\n",
    "        return\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        valid_loss_info = self.shared_step(batch, \"valid\")\n",
    "        self.validation_step_outputs.append(valid_loss_info)\n",
    "        return valid_loss_info\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.shared_epoch_end(self.validation_step_outputs, \"valid\")\n",
    "        self.validation_step_outputs.clear()\n",
    "        return\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        test_loss_info = self.shared_step(batch, \"test\")\n",
    "        self.test_step_outputs.append(test_loss_info)\n",
    "        return test_loss_info\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.shared_epoch_end(self.test_step_outputs, \"test\")\n",
    "        # empty set output list\n",
    "        self.test_step_outputs.clear()\n",
    "        return\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-4)\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_MAX, eta_min=1e-5)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "        return\n",
    "    def on_save_checkpoint(self, checkpoint):\n",
    "        # Save hyperparameters in the checkpoint\n",
    "        checkpoint['hyper_parameters'] = {\n",
    "            'arch': self.arch_name,\n",
    "            'encoder_name': self.encoder_name,\n",
    "            'in_channels': self.in_channels,  # Assuming model has this attribute\n",
    "            'out_classes': self.out_classes,  # Assuming model has this attribute\n",
    "        }\n",
    "    @classmethod\n",
    "    def load_from_checkpoint(cls, checkpoint_path, **kwargs):\n",
    "        \"\"\"\n",
    "        Load model weights from a checkpoint and instantiate the model.\n",
    "\n",
    "        Parameters:\n",
    "        checkpoint_path (str): Path to the checkpoint file.\n",
    "        kwargs (dict): Additional arguments to pass to the model initialization.\n",
    "\n",
    "        Returns:\n",
    "        DeepV_plus: Model instance with weights loaded from the checkpoint.\n",
    "        \"\"\"\n",
    "        # Load the checkpoint\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "        \n",
    "        # Get model parameters from the checkpoint\n",
    "        model_params = checkpoint['hyper_parameters']\n",
    "\n",
    "        # Create a new instance of the model using parameters from the checkpoint\n",
    "        model = cls(\n",
    "            arch=kwargs.get('arch', model_params['arch']),\n",
    "            encoder_name=kwargs.get('encoder_name', model_params['encoder_name']),\n",
    "            in_channels=kwargs.get('in_channels', model_params['in_channels']),\n",
    "            out_classes=kwargs.get('out_classes', model_params['out_classes']),\n",
    "        )\n",
    "        \n",
    "        # Load the state dictionary into the model\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "\n",
    "def train_deep_model(deepvPlus:DeepV_plus):\n",
    "    wandb.finish()\n",
    "    # Initialize WandbLogger\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"DeeplabV3Plus\",  # Your Wandb project name\n",
    "        name=f\"{deepvPlus.arch_name}-{deepvPlus.encoder_name}\",   # Experiment name\n",
    "        log_model=True,  # Log model checkpoints to Wandb\n",
    "        reinit=True \n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"deepCheckpoints/\",  # Directory to save checkpoints\n",
    "        filename=f\"{deepvPlus.arch_name}-{deepvPlus.encoder_name}\",  # Naming convention for the checkpoints\n",
    "        monitor=\"val_loss\",  # Metric to monitor for checkpoint saving\n",
    "        save_top_k=1,  # Save top 1 models with the best 'val_loss'\n",
    "        mode=\"min\",  # Save models with minimum 'val_loss'\n",
    "        save_last=True,  # Also save the latest checkpoint\n",
    "        verbose=True,  # Verbosity of saving messages\n",
    "        enable_version_counter=False,\n",
    "    )\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS, \n",
    "        log_every_n_steps=1, \n",
    "        callbacks=[checkpoint_callback],  # Add the checkpoint callback here\n",
    "        logger=wandb_logger  # Attach the Wandb logger\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        deepvPlus,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "\n",
    "    valid_metrics = trainer.validate(deepvPlus, dataloaders=val_dataloader, verbose=False)\n",
    "    print(valid_metrics)\n",
    "\n",
    "    test_metrics = trainer.test(deepvPlus, dataloaders=test_dataloader, verbose=False)\n",
    "    print(test_metrics)\n",
    "\n",
    "    # smp_model = deepvPlus.model\n",
    "\n",
    "    # commit_info = smp_model.save_pretrained(\n",
    "    #     save_directory=\"saved_models/DeepLabv3Plus\",\n",
    "    # )\n",
    "\n",
    "    clear_gpu_memory(deepvPlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_name):\n",
    "    # Load the model from the checkpoint\n",
    "    trainer = pl.Trainer(max_epochs=1000)\n",
    "    deepvPlus = DeepV_plus.load_from_checkpoint(f\"deepCheckpoints/{checkpoint_name}.ckpt\")\n",
    "    \n",
    "    valid_metrics = trainer.validate(deepvPlus, dataloaders=val_dataloader, verbose=False)\n",
    "    print(valid_metrics)\n",
    "\n",
    "    test_metrics = trainer.test(deepvPlus, dataloaders=test_dataloader, verbose=False)\n",
    "    print(test_metrics)\n",
    "    clear_gpu_memory(deepvPlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m2180153\u001b[0m (\u001b[33m2180153-wits-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240921_125024-p7zspisu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34/runs/p7zspisu' target=\"_blank\">deeplabv3plus-resnet34</a></strong> to <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34/runs/p7zspisu' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34/runs/p7zspisu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Tumi\\Other Subjects\\CV\\ComputerVisionLab\\Lab3\\deepCheckpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type          | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model   | DeepLabV3Plus | 22.4 M | train\n",
      "1 | loss_fn | DiceLoss      | 0      | train\n",
      "--------------------------------------------------\n",
      "22.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.4 M    Total params\n",
      "89.751    Total estimated model params size (MB)\n",
      "173       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 20/20 [00:02<00:00, 10.00it/s, v_num=pisu, val_loss=0.346, valid_per_image_iou=0.781, valid_dataset_iou=0.780, valid_f1_score=0.877]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 20: 'val_loss' reached 0.31060 (best 0.31060), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 20/20 [00:01<00:00, 11.00it/s, v_num=pisu, val_loss=0.152, valid_per_image_iou=0.915, valid_dataset_iou=0.915, valid_f1_score=0.956, train_per_image_iou=0.754, train_dataset_iou=0.735, train_f1_score=0.847]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 40: 'val_loss' reached 0.16541 (best 0.16541), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 20/20 [00:01<00:00, 10.58it/s, v_num=pisu, val_loss=0.103, valid_per_image_iou=0.947, valid_dataset_iou=0.947, valid_f1_score=0.973, train_per_image_iou=0.872, train_dataset_iou=0.872, train_f1_score=0.932]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 60: 'val_loss' reached 0.12245 (best 0.12245), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 20/20 [00:01<00:00, 10.56it/s, v_num=pisu, val_loss=0.0845, valid_per_image_iou=0.963, valid_dataset_iou=0.963, valid_f1_score=0.981, train_per_image_iou=0.918, train_dataset_iou=0.918, train_f1_score=0.957]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 80: 'val_loss' reached 0.09736 (best 0.09736), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 20/20 [00:01<00:00, 10.28it/s, v_num=pisu, val_loss=0.0701, valid_per_image_iou=0.975, valid_dataset_iou=0.975, valid_f1_score=0.987, train_per_image_iou=0.940, train_dataset_iou=0.940, train_f1_score=0.969]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 100: 'val_loss' reached 0.07913 (best 0.07913), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 20/20 [00:01<00:00, 10.64it/s, v_num=pisu, val_loss=0.0625, valid_per_image_iou=0.968, valid_dataset_iou=0.968, valid_f1_score=0.984, train_per_image_iou=0.955, train_dataset_iou=0.955, train_f1_score=0.977]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 120: 'val_loss' reached 0.06596 (best 0.06596), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 20/20 [00:01<00:00, 10.61it/s, v_num=pisu, val_loss=0.0526, valid_per_image_iou=0.979, valid_dataset_iou=0.979, valid_f1_score=0.989, train_per_image_iou=0.966, train_dataset_iou=0.966, train_f1_score=0.983]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 140: 'val_loss' reached 0.05587 (best 0.05587), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 20/20 [00:01<00:00, 10.68it/s, v_num=pisu, val_loss=0.0453, valid_per_image_iou=0.982, valid_dataset_iou=0.982, valid_f1_score=0.991, train_per_image_iou=0.972, train_dataset_iou=0.972, train_f1_score=0.986]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 160: 'val_loss' reached 0.04787 (best 0.04787), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 20/20 [00:01<00:00, 10.40it/s, v_num=pisu, val_loss=0.0422, valid_per_image_iou=0.984, valid_dataset_iou=0.984, valid_f1_score=0.992, train_per_image_iou=0.977, train_dataset_iou=0.977, train_f1_score=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 180: 'val_loss' reached 0.04189 (best 0.04189), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 20/20 [00:01<00:00, 10.53it/s, v_num=pisu, val_loss=0.0369, valid_per_image_iou=0.984, valid_dataset_iou=0.984, valid_f1_score=0.992, train_per_image_iou=0.980, train_dataset_iou=0.980, train_f1_score=0.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 200: 'val_loss' reached 0.03687 (best 0.03687), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 20/20 [00:01<00:00, 10.51it/s, v_num=pisu, val_loss=0.0321, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.993, train_per_image_iou=0.983, train_dataset_iou=0.983, train_f1_score=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 220: 'val_loss' reached 0.03295 (best 0.03295), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 20/20 [00:01<00:00, 10.58it/s, v_num=pisu, val_loss=0.0295, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.984, train_dataset_iou=0.984, train_f1_score=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 240: 'val_loss' reached 0.02971 (best 0.02971), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, v_num=pisu, val_loss=0.0284, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.986, train_dataset_iou=0.986, train_f1_score=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 260: 'val_loss' reached 0.02725 (best 0.02725), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, v_num=pisu, val_loss=0.0246, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.987, train_dataset_iou=0.987, train_f1_score=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 280: 'val_loss' reached 0.02519 (best 0.02519), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 20/20 [00:01<00:00, 10.64it/s, v_num=pisu, val_loss=0.0243, valid_per_image_iou=0.989, valid_dataset_iou=0.989, valid_f1_score=0.994, train_per_image_iou=0.987, train_dataset_iou=0.987, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 300: 'val_loss' reached 0.02341 (best 0.02341), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 20/20 [00:01<00:00, 10.55it/s, v_num=pisu, val_loss=0.0226, valid_per_image_iou=0.989, valid_dataset_iou=0.989, valid_f1_score=0.994, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 320: 'val_loss' reached 0.02201 (best 0.02201), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 20/20 [00:01<00:00, 10.69it/s, v_num=pisu, val_loss=0.0219, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 340: 'val_loss' reached 0.02076 (best 0.02076), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, v_num=pisu, val_loss=0.0205, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 360: 'val_loss' reached 0.01978 (best 0.01978), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, v_num=pisu, val_loss=0.0196, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 380: 'val_loss' reached 0.01906 (best 0.01906), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 20/20 [00:01<00:00, 10.75it/s, v_num=pisu, val_loss=0.0191, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 400: 'val_loss' reached 0.01852 (best 0.01852), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 20/20 [00:01<00:00, 10.38it/s, v_num=pisu, val_loss=0.0182, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 420: 'val_loss' reached 0.01785 (best 0.01785), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 20/20 [00:01<00:00, 10.48it/s, v_num=pisu, val_loss=0.0181, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 440: 'val_loss' reached 0.01745 (best 0.01745), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, v_num=pisu, val_loss=0.0175, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 460: 'val_loss' reached 0.01708 (best 0.01708), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 20/20 [00:01<00:00, 10.24it/s, v_num=pisu, val_loss=0.0168, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 480: 'val_loss' reached 0.01677 (best 0.01677), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 20/20 [00:01<00:00, 10.08it/s, v_num=pisu, val_loss=0.0172, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 500: 'val_loss' reached 0.01638 (best 0.01638), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 20/20 [00:01<00:00, 10.36it/s, v_num=pisu, val_loss=0.0168, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 520: 'val_loss' reached 0.01633 (best 0.01633), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, v_num=pisu, val_loss=0.0171, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 540: 'val_loss' reached 0.01613 (best 0.01613), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 20/20 [00:01<00:00, 10.29it/s, v_num=pisu, val_loss=0.0162, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 560: 'val_loss' reached 0.01607 (best 0.01607), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 20/20 [00:01<00:00, 10.62it/s, v_num=pisu, val_loss=0.0163, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 580: 'val_loss' reached 0.01587 (best 0.01587), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:01<00:00, 10.42it/s, v_num=pisu, val_loss=0.0162, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 600: 'val_loss' reached 0.01584 (best 0.01584), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:05<00:00,  3.94it/s, v_num=pisu, val_loss=0.0162, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  9.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'val_loss': 0.016173720359802246, 'valid_per_image_iou': 0.9909735321998596, 'valid_dataset_iou': 0.9909728169441223, 'valid_f1_score': 0.9954655170440674}]\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.01it/s]\n",
      "[{'val_loss': 0.01553952693939209, 'test_per_image_iou': 0.9910772442817688, 'test_dataset_iou': 0.9910755753517151, 'test_f1_score': 0.9955173134803772}]\n"
     ]
    }
   ],
   "source": [
    "deepvPlus_model = DeepV_plus(\"deeplabv3plus\", \"resnet34\", in_channels=3, out_classes=2)\n",
    "train_deep_model(deepvPlus_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>test_dataset_iou</td><td>▁</td></tr><tr><td>test_f1_score</td><td>▁</td></tr><tr><td>test_per_image_iou</td><td>▁</td></tr><tr><td>train_dataset_iou</td><td>▁▅▆▇▇▇▇███████████████████████</td></tr><tr><td>train_f1_score</td><td>▁▅▆▇▇▇████████████████████████</td></tr><tr><td>train_per_image_iou</td><td>▁▅▆▇▇▇▇███████████████████████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▇▄▃▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_dataset_iou</td><td>▁▅▇▇▇▇█████████████████████████</td></tr><tr><td>valid_f1_score</td><td>▁▆▇▇█▇█████████████████████████</td></tr><tr><td>valid_per_image_iou</td><td>▁▅▇▇▇▇█████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>test_dataset_iou</td><td>0.99108</td></tr><tr><td>test_f1_score</td><td>0.99552</td></tr><tr><td>test_per_image_iou</td><td>0.99108</td></tr><tr><td>train_dataset_iou</td><td>0.99052</td></tr><tr><td>train_f1_score</td><td>0.99524</td></tr><tr><td>train_per_image_iou</td><td>0.99052</td></tr><tr><td>trainer/global_step</td><td>600</td></tr><tr><td>val_loss</td><td>0.01554</td></tr><tr><td>valid_dataset_iou</td><td>0.99097</td></tr><tr><td>valid_f1_score</td><td>0.99547</td></tr><tr><td>valid_per_image_iou</td><td>0.99097</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deeplabv3plus-resnet34</strong> at: <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34/runs/p7zspisu' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34/runs/p7zspisu</a><br/> View project at: <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240921_125024-p7zspisu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240921_125320-vfdzhdac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d/runs/vfdzhdac' target=\"_blank\">deeplabv3plus-resnext50_32x4d</a></strong> to <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d/runs/vfdzhdac' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d/runs/vfdzhdac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Tumi\\Other Subjects\\CV\\ComputerVisionLab\\Lab3\\deepCheckpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type          | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model   | DeepLabV3Plus | 26.1 M | train\n",
      "1 | loss_fn | DiceLoss      | 0      | train\n",
      "--------------------------------------------------\n",
      "26.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.1 M    Total params\n",
      "104.599   Total estimated model params size (MB)\n",
      "208       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 20/20 [00:03<00:00,  6.25it/s, v_num=hdac, val_loss=0.342, valid_per_image_iou=0.805, valid_dataset_iou=0.805, valid_f1_score=0.892]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 20: 'val_loss' reached 0.29444 (best 0.29444), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 20/20 [00:03<00:00,  6.04it/s, v_num=hdac, val_loss=0.163, valid_per_image_iou=0.876, valid_dataset_iou=0.876, valid_f1_score=0.934, train_per_image_iou=0.771, train_dataset_iou=0.761, train_f1_score=0.865]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 40: 'val_loss' reached 0.16729 (best 0.16729), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 20/20 [00:03<00:00,  5.97it/s, v_num=hdac, val_loss=0.106, valid_per_image_iou=0.957, valid_dataset_iou=0.957, valid_f1_score=0.978, train_per_image_iou=0.853, train_dataset_iou=0.853, train_f1_score=0.920]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 60: 'val_loss' reached 0.12167 (best 0.12167), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 20/20 [00:03<00:00,  5.98it/s, v_num=hdac, val_loss=0.0836, valid_per_image_iou=0.966, valid_dataset_iou=0.966, valid_f1_score=0.983, train_per_image_iou=0.913, train_dataset_iou=0.912, train_f1_score=0.954]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 80: 'val_loss' reached 0.09370 (best 0.09370), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 20/20 [00:03<00:00,  6.00it/s, v_num=hdac, val_loss=0.0638, valid_per_image_iou=0.974, valid_dataset_iou=0.974, valid_f1_score=0.987, train_per_image_iou=0.945, train_dataset_iou=0.945, train_f1_score=0.972]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 100: 'val_loss' reached 0.07444 (best 0.07444), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 20/20 [00:03<00:00,  5.80it/s, v_num=hdac, val_loss=0.0565, valid_per_image_iou=0.978, valid_dataset_iou=0.978, valid_f1_score=0.989, train_per_image_iou=0.963, train_dataset_iou=0.963, train_f1_score=0.981]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 120: 'val_loss' reached 0.06117 (best 0.06117), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 20/20 [00:03<00:00,  5.88it/s, v_num=hdac, val_loss=0.0474, valid_per_image_iou=0.983, valid_dataset_iou=0.983, valid_f1_score=0.991, train_per_image_iou=0.970, train_dataset_iou=0.970, train_f1_score=0.985]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 140: 'val_loss' reached 0.05071 (best 0.05071), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 20/20 [00:03<00:00,  6.00it/s, v_num=hdac, val_loss=0.0397, valid_per_image_iou=0.985, valid_dataset_iou=0.985, valid_f1_score=0.993, train_per_image_iou=0.977, train_dataset_iou=0.977, train_f1_score=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 160: 'val_loss' reached 0.04263 (best 0.04263), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s, v_num=hdac, val_loss=0.0346, valid_per_image_iou=0.986, valid_dataset_iou=0.986, valid_f1_score=0.993, train_per_image_iou=0.982, train_dataset_iou=0.982, train_f1_score=0.991]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 180: 'val_loss' reached 0.03667 (best 0.03667), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 20/20 [00:03<00:00,  5.92it/s, v_num=hdac, val_loss=0.0312, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.984, train_dataset_iou=0.984, train_f1_score=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 200: 'val_loss' reached 0.03228 (best 0.03228), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 20/20 [00:03<00:00,  5.94it/s, v_num=hdac, val_loss=0.0278, valid_per_image_iou=0.989, valid_dataset_iou=0.989, valid_f1_score=0.994, train_per_image_iou=0.986, train_dataset_iou=0.986, train_f1_score=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 220: 'val_loss' reached 0.02870 (best 0.02870), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 20/20 [00:03<00:00,  5.89it/s, v_num=hdac, val_loss=0.0252, valid_per_image_iou=0.989, valid_dataset_iou=0.989, valid_f1_score=0.995, train_per_image_iou=0.987, train_dataset_iou=0.987, train_f1_score=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 240: 'val_loss' reached 0.02603 (best 0.02603), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 20/20 [00:03<00:00,  5.92it/s, v_num=hdac, val_loss=0.0235, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 260: 'val_loss' reached 0.02390 (best 0.02390), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 20/20 [00:03<00:00,  5.92it/s, v_num=hdac, val_loss=0.0203, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 280: 'val_loss' reached 0.02212 (best 0.02212), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 20/20 [00:03<00:00,  5.84it/s, v_num=hdac, val_loss=0.0201, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 300: 'val_loss' reached 0.02053 (best 0.02053), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 20/20 [00:03<00:00,  5.79it/s, v_num=hdac, val_loss=0.0188, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 320: 'val_loss' reached 0.01934 (best 0.01934), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 20/20 [00:03<00:00,  5.77it/s, v_num=hdac, val_loss=0.0184, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.996, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 340: 'val_loss' reached 0.01840 (best 0.01840), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s, v_num=hdac, val_loss=0.0176, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.996, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 360: 'val_loss' reached 0.01759 (best 0.01759), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s, v_num=hdac, val_loss=0.0163, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 380: 'val_loss' reached 0.01685 (best 0.01685), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 20/20 [00:03<00:00,  5.90it/s, v_num=hdac, val_loss=0.0162, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 400: 'val_loss' reached 0.01636 (best 0.01636), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 20/20 [00:03<00:00,  6.00it/s, v_num=hdac, val_loss=0.0157, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 420: 'val_loss' reached 0.01581 (best 0.01581), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s, v_num=hdac, val_loss=0.016, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 440: 'val_loss' reached 0.01552 (best 0.01552), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 20/20 [00:03<00:00,  5.80it/s, v_num=hdac, val_loss=0.0152, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 460: 'val_loss' reached 0.01516 (best 0.01516), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 20/20 [00:03<00:00,  5.99it/s, v_num=hdac, val_loss=0.0151, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 480: 'val_loss' reached 0.01487 (best 0.01487), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 20/20 [00:03<00:00,  5.87it/s, v_num=hdac, val_loss=0.015, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 500: 'val_loss' reached 0.01472 (best 0.01472), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 20/20 [00:03<00:00,  5.75it/s, v_num=hdac, val_loss=0.0149, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 520: 'val_loss' reached 0.01449 (best 0.01449), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 20/20 [00:03<00:00,  5.92it/s, v_num=hdac, val_loss=0.0144, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 540: 'val_loss' reached 0.01449 (best 0.01449), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 20/20 [00:03<00:00,  5.98it/s, v_num=hdac, val_loss=0.0142, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 560: 'val_loss' reached 0.01428 (best 0.01428), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 20/20 [00:03<00:00,  5.97it/s, v_num=hdac, val_loss=0.0144, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 580: 'val_loss' reached 0.01420 (best 0.01420), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:03<00:00,  5.93it/s, v_num=hdac, val_loss=0.0145, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 600: 'val_loss' reached 0.01411 (best 0.01411), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:06<00:00,  3.31it/s, v_num=hdac, val_loss=0.0145, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'val_loss': 0.014513224363327026, 'valid_per_image_iou': 0.9921114444732666, 'valid_dataset_iou': 0.9921113848686218, 'valid_f1_score': 0.996039628982544}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 31.21it/s]\n",
      "[{'val_loss': 0.013683512806892395, 'test_per_image_iou': 0.9918500185012817, 'test_dataset_iou': 0.9918493032455444, 'test_f1_score': 0.9959075450897217}]\n"
     ]
    }
   ],
   "source": [
    "deepvPlus_model = DeepV_plus(\"deeplabv3plus\", \"resnext50_32x4d\", in_channels=3, out_classes=2)\n",
    "train_deep_model(deepvPlus_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>test_dataset_iou</td><td>▁</td></tr><tr><td>test_f1_score</td><td>▁</td></tr><tr><td>test_per_image_iou</td><td>▁</td></tr><tr><td>train_dataset_iou</td><td>▁▄▆▇▇▇████████████████████████</td></tr><tr><td>train_f1_score</td><td>▁▄▆▇▇▇████████████████████████</td></tr><tr><td>train_per_image_iou</td><td>▁▄▆▇▇▇████████████████████████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▇▄▃▂▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_dataset_iou</td><td>▁▄▇▇▇▇█████████████████████████</td></tr><tr><td>valid_f1_score</td><td>▁▄▇▇▇██████████████████████████</td></tr><tr><td>valid_per_image_iou</td><td>▁▄▇▇▇▇█████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>test_dataset_iou</td><td>0.99185</td></tr><tr><td>test_f1_score</td><td>0.99591</td></tr><tr><td>test_per_image_iou</td><td>0.99185</td></tr><tr><td>train_dataset_iou</td><td>0.99138</td></tr><tr><td>train_f1_score</td><td>0.99567</td></tr><tr><td>train_per_image_iou</td><td>0.99138</td></tr><tr><td>trainer/global_step</td><td>600</td></tr><tr><td>val_loss</td><td>0.01368</td></tr><tr><td>valid_dataset_iou</td><td>0.99211</td></tr><tr><td>valid_f1_score</td><td>0.99604</td></tr><tr><td>valid_per_image_iou</td><td>0.99211</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deeplabv3plus-resnext50_32x4d</strong> at: <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d/runs/vfdzhdac' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d/runs/vfdzhdac</a><br/> View project at: <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240921_125320-vfdzhdac\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240921_125706-23fxqho7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032/runs/23fxqho7' target=\"_blank\">deeplabv3plus-timm-regnetx_032</a></strong> to <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032/runs/23fxqho7' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032/runs/23fxqho7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Tumi\\Other Subjects\\CV\\ComputerVisionLab\\Lab3\\deepCheckpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type          | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model   | DeepLabV3Plus | 16.1 M | train\n",
      "1 | loss_fn | DiceLoss      | 0      | train\n",
      "--------------------------------------------------\n",
      "16.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.1 M    Total params\n",
      "64.362    Total estimated model params size (MB)\n",
      "586       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 20/20 [00:04<00:00,  4.86it/s, v_num=qho7, val_loss=0.366, valid_per_image_iou=0.746, valid_dataset_iou=0.746, valid_f1_score=0.854]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 20: 'val_loss' reached 0.31195 (best 0.31195), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 20/20 [00:04<00:00,  4.89it/s, v_num=qho7, val_loss=0.168, valid_per_image_iou=0.870, valid_dataset_iou=0.870, valid_f1_score=0.930, train_per_image_iou=0.743, train_dataset_iou=0.729, train_f1_score=0.843]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 40: 'val_loss' reached 0.16316 (best 0.16316), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 20/20 [00:04<00:00,  4.87it/s, v_num=qho7, val_loss=0.112, valid_per_image_iou=0.923, valid_dataset_iou=0.923, valid_f1_score=0.960, train_per_image_iou=0.861, train_dataset_iou=0.861, train_f1_score=0.925]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 60: 'val_loss' reached 0.12036 (best 0.12036), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 20/20 [00:03<00:00,  5.03it/s, v_num=qho7, val_loss=0.0857, valid_per_image_iou=0.955, valid_dataset_iou=0.955, valid_f1_score=0.977, train_per_image_iou=0.905, train_dataset_iou=0.905, train_f1_score=0.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 80: 'val_loss' reached 0.09387 (best 0.09387), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 20/20 [00:03<00:00,  5.02it/s, v_num=qho7, val_loss=0.0677, valid_per_image_iou=0.972, valid_dataset_iou=0.972, valid_f1_score=0.986, train_per_image_iou=0.933, train_dataset_iou=0.933, train_f1_score=0.966]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 100: 'val_loss' reached 0.07396 (best 0.07396), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 20/20 [00:04<00:00,  4.83it/s, v_num=qho7, val_loss=0.0544, valid_per_image_iou=0.976, valid_dataset_iou=0.976, valid_f1_score=0.988, train_per_image_iou=0.954, train_dataset_iou=0.954, train_f1_score=0.977]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 120: 'val_loss' reached 0.05972 (best 0.05972), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 20/20 [00:04<00:00,  4.82it/s, v_num=qho7, val_loss=0.048, valid_per_image_iou=0.978, valid_dataset_iou=0.978, valid_f1_score=0.989, train_per_image_iou=0.966, train_dataset_iou=0.966, train_f1_score=0.982] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 140: 'val_loss' reached 0.04962 (best 0.04962), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 20/20 [00:04<00:00,  4.78it/s, v_num=qho7, val_loss=0.0405, valid_per_image_iou=0.981, valid_dataset_iou=0.981, valid_f1_score=0.990, train_per_image_iou=0.974, train_dataset_iou=0.974, train_f1_score=0.987]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 160: 'val_loss' reached 0.04230 (best 0.04230), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 20/20 [00:04<00:00,  4.65it/s, v_num=qho7, val_loss=0.0351, valid_per_image_iou=0.983, valid_dataset_iou=0.983, valid_f1_score=0.991, train_per_image_iou=0.977, train_dataset_iou=0.977, train_f1_score=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 180: 'val_loss' reached 0.03693 (best 0.03693), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 20/20 [00:04<00:00,  4.95it/s, v_num=qho7, val_loss=0.0325, valid_per_image_iou=0.983, valid_dataset_iou=0.983, valid_f1_score=0.991, train_per_image_iou=0.980, train_dataset_iou=0.980, train_f1_score=0.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 200: 'val_loss' reached 0.03274 (best 0.03274), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 20/20 [00:04<00:00,  4.64it/s, v_num=qho7, val_loss=0.0296, valid_per_image_iou=0.985, valid_dataset_iou=0.985, valid_f1_score=0.992, train_per_image_iou=0.981, train_dataset_iou=0.981, train_f1_score=0.991]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 220: 'val_loss' reached 0.02951 (best 0.02951), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 20/20 [00:04<00:00,  4.79it/s, v_num=qho7, val_loss=0.0266, valid_per_image_iou=0.985, valid_dataset_iou=0.985, valid_f1_score=0.993, train_per_image_iou=0.983, train_dataset_iou=0.983, train_f1_score=0.991]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 240: 'val_loss' reached 0.02687 (best 0.02687), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 20/20 [00:04<00:00,  4.69it/s, v_num=qho7, val_loss=0.0246, valid_per_image_iou=0.986, valid_dataset_iou=0.986, valid_f1_score=0.993, train_per_image_iou=0.984, train_dataset_iou=0.984, train_f1_score=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 260: 'val_loss' reached 0.02480 (best 0.02480), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 20/20 [00:04<00:00,  4.86it/s, v_num=qho7, val_loss=0.0236, valid_per_image_iou=0.985, valid_dataset_iou=0.985, valid_f1_score=0.992, train_per_image_iou=0.985, train_dataset_iou=0.985, train_f1_score=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 280: 'val_loss' reached 0.02299 (best 0.02299), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 20/20 [00:04<00:00,  4.97it/s, v_num=qho7, val_loss=0.022, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.993, train_per_image_iou=0.986, train_dataset_iou=0.986, train_f1_score=0.993] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 300: 'val_loss' reached 0.02161 (best 0.02161), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 20/20 [00:04<00:00,  4.99it/s, v_num=qho7, val_loss=0.0209, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.993, train_per_image_iou=0.986, train_dataset_iou=0.986, train_f1_score=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 320: 'val_loss' reached 0.02031 (best 0.02031), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 20/20 [00:04<00:00,  4.99it/s, v_num=qho7, val_loss=0.0199, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.993, train_per_image_iou=0.987, train_dataset_iou=0.987, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 340: 'val_loss' reached 0.01927 (best 0.01927), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 20/20 [00:04<00:00,  4.98it/s, v_num=qho7, val_loss=0.0193, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.994, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 360: 'val_loss' reached 0.01852 (best 0.01852), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 20/20 [00:04<00:00,  4.86it/s, v_num=qho7, val_loss=0.0188, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.994, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 380: 'val_loss' reached 0.01782 (best 0.01782), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 20/20 [00:04<00:00,  4.97it/s, v_num=qho7, val_loss=0.0184, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.994, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 400: 'val_loss' reached 0.01718 (best 0.01718), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 20/20 [00:04<00:00,  4.92it/s, v_num=qho7, val_loss=0.0185, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.993, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 420: 'val_loss' reached 0.01683 (best 0.01683), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 20/20 [00:04<00:00,  4.90it/s, v_num=qho7, val_loss=0.0175, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 440: 'val_loss' reached 0.01625 (best 0.01625), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 20/20 [00:04<00:00,  4.78it/s, v_num=qho7, val_loss=0.0171, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 460: 'val_loss' reached 0.01602 (best 0.01602), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 20/20 [00:04<00:00,  4.97it/s, v_num=qho7, val_loss=0.0169, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 480: 'val_loss' reached 0.01571 (best 0.01571), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 20/20 [00:04<00:00,  4.89it/s, v_num=qho7, val_loss=0.017, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 500: 'val_loss' reached 0.01548 (best 0.01548), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 20/20 [00:04<00:00,  4.94it/s, v_num=qho7, val_loss=0.0167, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 520: 'val_loss' reached 0.01537 (best 0.01537), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 20/20 [00:04<00:00,  4.91it/s, v_num=qho7, val_loss=0.0167, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 540: 'val_loss' reached 0.01526 (best 0.01526), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 20/20 [00:04<00:00,  4.94it/s, v_num=qho7, val_loss=0.0164, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 560: 'val_loss' reached 0.01508 (best 0.01508), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 20/20 [00:04<00:00,  4.89it/s, v_num=qho7, val_loss=0.016, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 580: 'val_loss' reached 0.01503 (best 0.01503), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:04<00:00,  4.81it/s, v_num=qho7, val_loss=0.0166, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 600: 'val_loss' reached 0.01489 (best 0.01489), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:06<00:00,  3.27it/s, v_num=qho7, val_loss=0.0166, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  9.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'val_loss': 0.016593188047409058, 'valid_per_image_iou': 0.9882156252861023, 'valid_dataset_iou': 0.9882150292396545, 'valid_f1_score': 0.9940721392631531}]\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 32.63it/s]\n",
      "[{'val_loss': 0.014644607901573181, 'test_per_image_iou': 0.9886478185653687, 'test_dataset_iou': 0.9886442422866821, 'test_f1_score': 0.994289219379425}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "deepvPlus_model = DeepV_plus(\"deeplabv3plus\", \"timm-regnetx_032\", in_channels=3, out_classes=2)\n",
    "train_deep_model(deepvPlus_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_38572\\3189538887.py:189: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 37.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'val_loss': 0.016173720359802246, 'valid_per_image_iou': 0.9909735321998596, 'valid_dataset_iou': 0.9909728169441223, 'valid_f1_score': 0.9954655170440674}]\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.99it/s] \n",
      "[{'val_loss': 0.01553952693939209, 'test_per_image_iou': 0.9910772442817688, 'test_dataset_iou': 0.9910755753517151, 'test_f1_score': 0.9955173134803772}]\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint(\"deeplabv3plus-resnet34\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
