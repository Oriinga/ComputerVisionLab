{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Group Name : Unfiltered Commentary\n",
    "\n",
    "- Raees Moosa : 2322203\n",
    "- Oriinga Maudu : 2433303\n",
    "- Tumi Jourdan : 2180153\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is just for me since gpu bugged'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"this is just for me since gpu bugged\"\"\"\n",
    "# %env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN IMPORTS \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchviz import make_dot\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torchvision.transforms as T\n",
    "from skimage import transform as sktf\n",
    "from skimage.util import random_noise\n",
    "import random\n",
    "\n",
    "# https://pytorch.org/tutorials/beginner/introyt/modelsyt_tutorial.html - documetnation on how to make a pytorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing \n",
    "- dataloaders\n",
    "- augmentation pipeline\n",
    "## Add notes on this here (what is happening)\n",
    "- added some transforms that are vert and hor flips including rotation\n",
    "- [ ] TODO Add random noise shapes in the image outside the mask maybe that will help the model learn better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader\n",
    "# the images are loaded as float32 and normalised\n",
    "# the mask is thresholded at 0.5 \n",
    "\"\"\" the permute is needed since the format for image tensors must be (C, H, W)\n",
    "But when we read from opencv the shape is (H, W, C)\n",
    "and the mask must be of dim (1, H, W) since single channel - unsqueeze add this channel\n",
    "\"\"\"\n",
    "# returned as tensors \n",
    "\n",
    "class PuzzleDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None, num_transforms=0,include_inverse_mask=True):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.num_transforms = num_transforms\n",
    "        self.include_inverse_mask=include_inverse_mask\n",
    "        images = sorted(os.listdir(img_dir))\n",
    "        masks = sorted(os.listdir(mask_dir))\n",
    "        self.data = []\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            img_path = os.path.join(self.img_dir, images[i])\n",
    "            mask_path = os.path.join(self.mask_dir, masks[i])\n",
    "\n",
    "          \n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (512, 512))\n",
    "            image = image.astype(np.float32)/255.0\n",
    "            # image = Image.fromarray(image)  \n",
    "\n",
    "            \n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.resize(mask, (512,512))\n",
    "            mask = (mask > 0.5).astype(np.float32) \n",
    "            # mask = Image.fromarray(mask)  #   PIL image needed for transforms\n",
    "\n",
    "            # store the original image and mask\n",
    "            self.append_image_mask(image, mask)\n",
    "\n",
    "            # do transformations \n",
    "            for _ in range(self.num_transforms):\n",
    "                transformed_image, transformed_mask = self.apply_transform(image, mask)\n",
    "                self.append_image_mask(transformed_image, transformed_mask)\n",
    "\n",
    "    def apply_transform(self, image, mask):\n",
    "        \"\"\"Apply deterministic transformations to both image and mask\n",
    "        This is imortant since using the torchvision.transforms was givin a random transform\n",
    "        for both image and mask -> they didn't match up\"\"\"\n",
    "        if self.transform:\n",
    "            \n",
    "            if random.random() > 0.5:\n",
    "                image = np.fliplr(image)\n",
    "                mask = np.fliplr(mask)\n",
    "\n",
    "           \n",
    "            if random.random() > 0.5:\n",
    "                image = np.flipud(image)\n",
    "                mask = np.flipud(mask)\n",
    "\n",
    "            # Apply rotation deterministically\n",
    "            angle = np.random.uniform(-30, 30)\n",
    "            image = sktf.rotate(image, angle, mode=\"edge\" , preserve_range=True)\n",
    "            mask = sktf.rotate(mask, angle, mode=\"edge\" , preserve_range=True)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def append_image_mask(self, image, mask):\n",
    "        \"\"\"need to store them as tensors.\"\"\"\n",
    "        image = torch.tensor(image.transpose((2, 0, 1)), dtype=torch.float32) # (C, H, W)\n",
    "        mask = torch.tensor(mask[None, ...], dtype=torch.float32)   # (1, H, W)\n",
    "\n",
    "       \n",
    "        if(self.include_inverse_mask):\n",
    "            inverse_mask = 1 - mask\n",
    "            combined_mask = torch.cat([inverse_mask, mask], dim=0)  # Combined (2, H, W)\n",
    "\n",
    "        \n",
    "            self.data.append((image, combined_mask))\n",
    "        else:\n",
    "            self.data.append((image,mask))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the training dataset\n",
    "- NOTE increasing batch size to 5 since our dataset size is up to 40 now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "torch.Size([2, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Axes: >, <matplotlib.image.AxesImage at 0x239a707d090>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  list of transformations\n",
    "# transform_list = [\n",
    "#     T.RandomHorizontalFlip(),\n",
    "#     T.RandomVerticalFlip(),\n",
    "#     T.RandomRotation(30),\n",
    "# ]\n",
    "\n",
    "\n",
    "train_dataset = PuzzleDataset(\n",
    "    img_dir=\"./images-1024x768/train/\",\n",
    "    mask_dir=\"./masks-1024x768/train/\", \n",
    "    transform=True,\n",
    "    num_transforms=3  \n",
    ")\n",
    "#since 10 images batches of 1 should be fine can do like batches of 2 i guess                        \n",
    "# note we now have more images since transform applied so maybe adjust batches\n",
    "train_loader = DataLoader(train_dataset,batch_size =2, shuffle=True)\n",
    "\n",
    "print(len(train_dataset.data))\n",
    "# # to visualise the images + masks are in correct pairing\n",
    "image, mask = train_dataset[6]\n",
    "\n",
    "image_np = (image.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "mask_np = mask.permute(1, 2, 0).numpy()\n",
    "print(mask.shape)\n",
    "\n",
    "\n",
    "#to collapse the separate channels of bg and fg mask\n",
    "if mask_np.shape[2] == 2:\n",
    "    mask_np = np.argmax(mask_np, axis=2)\n",
    "    \n",
    "plt.figure()\n",
    "plt.subplot(1,2,1), plt.imshow(image_np)\n",
    "plt.subplot(1,2,2), plt.imshow(mask_np, cmap=\"gray\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = PuzzleDataset(\n",
    "    img_dir=\"./images-1024x768/val/\",\n",
    "    mask_dir=\"./masks-1024x768/val/\", \n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "test_dataset = PuzzleDataset(img_dir = \"./images-1024x768/test/\",\n",
    "                            mask_dir = \"./masks-1024x768/test/\")\n",
    "#since 10 images batches of 1 should be fine can do like batches of 2 i guess                        \n",
    "test_loader = DataLoader(test_dataset,batch_size =1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Unet Construction\n",
    "## Add notes on this here (what is happening)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'start_epoch = load_checkpoint(model, optimizer)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Adding checkpoints as required and to avoid training everytime someone wants to test\"\"\"\n",
    "def save_checkpoint(model, optimizer, epoch, filename=\"checkpoint.pth\"):\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved at epoch {epoch}.\")\n",
    "\n",
    "\n",
    "# use as in training\n",
    "\"\"\"save_checkpoint(model, optimizer, epoch)\"\"\"\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename=\"checkpoint.pth\"):\n",
    "    if os.path.isfile(filename):\n",
    "        checkpoint = torch.load(filename)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "        print(f\"Checkpoint loaded from epoch {epoch}.\")\n",
    "        return epoch\n",
    "    else:\n",
    "        print(\"No checkpoint found.\")\n",
    "        return 0  # training from start ...\n",
    "\n",
    "# before training starts to load model\n",
    "\"\"\"start_epoch = load_checkpoint(model, optimizer)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" helper to clear the gpu of datasets and model\"\"\"\n",
    "def clear_gpu_memory(model=None, data_loaders=None):\n",
    "    \n",
    "    if model is not None:\n",
    "        model.cpu()\n",
    "        del model\n",
    "    \n",
    "    \n",
    "    if data_loaders is not None:\n",
    "        for loader in data_loaders:\n",
    "            del loader  \n",
    "    \n",
    "    #  garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vairant 1 : Using `torch.nn.ConvTranspose2d` for upsampling\n",
    "- We removed the softmax in the unet with convolve to get to the required number of output classes (ask richard).\n",
    "- Having the argmax inside the network caused issues with backprop so we only compute the raw logits and use these for the BCE loss\n",
    "then use the apply softmax outside when performing inference on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So this is the triple convolution, chat gpt says we should use normalization dont know if we should keep it\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.triple_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.triple_conv(x)\n",
    "    \n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Conv, self).__init__()\n",
    "        self.triple_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.triple_conv(x)\n",
    "\n",
    "    \n",
    "# the down module is what the unet uses during the first half \n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels,out_channels):\n",
    "        super(Down, self).__init__()\n",
    "        self.conv_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2,padding=0),\n",
    "            DoubleConv(in_channels,out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret_ = self.conv_pool(x)\n",
    "        return ret_\n",
    "\n",
    "# up transpose, \n",
    "class UpConvTranspose(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UpConvTranspose, self).__init__()\n",
    "        # to determine amount of out channels\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "        self.conv = Conv(out_channels, out_channels)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.up(x)\n",
    "        return self.conv(x)\n",
    "\n",
    "class UpBilinear(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UpBilinear, self).__init__()\n",
    "        # the bilinear is provided by the nn module, we set the mode to bilinear here\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = Conv(out_channels, out_channels)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.up(x)\n",
    "        return self.conv(x)\n",
    "    \n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,mode):\n",
    "        super(Up, self).__init__()\n",
    "        if(mode=='convtranspose'):\n",
    "            self.conv_pool = nn.Sequential(\n",
    "                UpConvTranspose(in_channels,out_channels),\n",
    "                Conv(out_channels,out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.conv_pool = nn.Sequential(\n",
    "                UpBilinear(in_channels,out_channels),\n",
    "                Conv(out_channels,out_channels)\n",
    "            )\n",
    "        \n",
    "        self.dconv = DoubleConv(out_channels*2,out_channels)\n",
    "    \n",
    "    def forward(self,x1,x2):\n",
    "        x = self.conv_pool(x1)\n",
    "        return self.dconv(torch.cat([x,x2],dim=1))\n",
    "\n",
    "    \n",
    "class SoftMax(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SoftMax, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.softmax(x)\n",
    "        return torch.argmax(x,dim=1)\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, variant='convtranspose'):\n",
    "        super(Unet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.variant = variant\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64,128)\n",
    "        self.down2 = Down(128,256)\n",
    "        self.down3 = Down(256,512)\n",
    "        self.down4 = Down(512,1024)\n",
    "        \n",
    "        self.up1 = Up(1024,512,variant)\n",
    "        self.up2 = Up(512, 256,variant)\n",
    "        self.up3 = Up(256, 128,variant)\n",
    "        self.up4 = Up(128, 64,variant)\n",
    "\n",
    "        self.outc = nn.Conv2d(64,2, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        \n",
    "        logits = self.outc(x)\n",
    "        \n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(preds, targets, threshold=0.5):\n",
    "    # Make sure predictions and targets are 4D: [batch_size, channels, height, width]\n",
    "    if preds.dim() == 3:\n",
    "        preds = preds.unsqueeze(0)  # Add batch dimension\n",
    "    if targets.dim() == 3:\n",
    "        targets = targets.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    preds = (torch.sigmoid(preds) > threshold).float()\n",
    "    \n",
    "    # Calculate intersection and union\n",
    "    intersection = torch.sum(preds * targets, dim=[2, 3])\n",
    "    union = torch.sum(preds, dim=[2, 3]) + torch.sum(targets, dim=[2, 3]) - intersection\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)  # Add small epsilon to avoid division by zero\n",
    "    \n",
    "    return iou.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: I just pushed to the cpu when I try putting the model on the gpu I get weird errors in training \n",
    "that I used up all the GPU memory maybe you wont get this error then just comment out `device=\"cpu\"\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'wandb' has no attribute 'init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnet variant 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# I forced the device to cpu since I have no gpu comment that line out!\u001b[39;00m\n\u001b[0;32m     10\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'wandb' has no attribute 'init'"
     ]
    }
   ],
   "source": [
    "\"\"\" Training UNET Variant 1\n",
    "    torch.nn.ConvTranspose2d \"\"\"\n",
    "\n",
    "import gc\n",
    "import wandb\n",
    "wandb.init(project=\"Unet variant 1\")\n",
    "\n",
    "# I forced the device to cpu since I have no gpu comment that line out!\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "\n",
    "\n",
    "# Model, criterion, and optimizer setup\n",
    "model = Unet(n_channels=3, n_classes=2, variant='convtranspose')\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     model = model.to('cuda:1')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "#  checkpoints if any\n",
    "start_epoch = load_checkpoint(model, optimizer, filename=\"var1_checkpoint.pth\")\n",
    "\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    \n",
    "    # print(torch.cuda.memory_summary())\n",
    "\n",
    "    \n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    train_iou = 0.0\n",
    "    \n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # outputs = outputs.float()\n",
    "        # outputs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "        # print(f\"Outputs min: {outputs.min()}, max: {outputs.max()}, shape: {outputs.shape}\")\n",
    "        # print(f\"Masks min: {masks.min()}, max: {masks.max()}, shape: {masks.shape}\")\n",
    "        \n",
    "        # BCE loss with logits \n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        #gradient clipping I dunno why we get nans\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        #softmax to logits to then get the IoU\n",
    "        \n",
    "        \n",
    "        #  loss and IoU\n",
    "        running_loss += loss.item()\n",
    "        train_iou += calculate_iou(outputs, masks)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_iou = train_iou / len(train_loader)\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_iou = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            val_iou += calculate_iou(outputs, masks)\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_iou = val_iou/ len(val_loader)\n",
    "\n",
    "\n",
    "    #  training and validation metrics to wandb\n",
    "    wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss, \"train_iou\": train_iou, \"val_iou\": val_iou})\n",
    "    \n",
    "    \n",
    "    # print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "    \n",
    "    # store model checkpoint if validation loss improves\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_checkpoint(model,optimizer, epoch, \"var1_checkpoint.pth\")\n",
    "        print(f\"Checkpoint saved at epoch {epoch + 1}\")\n",
    "\n",
    "    # model.cpu()\n",
    "    # del model\n",
    "    gc.collect() \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # print(torch.cuda.memory_summary())\n",
    "\n",
    "\n",
    "# close wandb run\n",
    "\n",
    "\n",
    "# run tensorboard --logdir=runs to see networkls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tensor_as_image(tensor, channel_num, channel_index, height_index, width_index):\n",
    "    # Move the tensor to CPU and convert it to a NumPy array\n",
    "    tensor_np = tensor.cpu().numpy()\n",
    "    if channel_index == 1:\n",
    "        tensor_np = tensor_np.squeeze(0)\n",
    "\n",
    "        channel_index -=1\n",
    "        height_index-=1\n",
    "        width_index-=1\n",
    "        \n",
    "    # Handle single-channel (grayscale) image\n",
    "    if channel_num == 1:\n",
    "        image_np = tensor_np.squeeze(channel_index)  # Remove the channel dimension\n",
    "        plt.imshow(image_np, cmap=\"gray\")\n",
    "        plt.title(\"Single-channel image\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Handle two-channel image (display channels separately)\n",
    "    elif channel_num == 2:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))  # Create 1 row, 2 columns\n",
    "        for i in range(2):\n",
    "            channel_image = tensor_np[i]  # Select each channel (e.g., 0 and 1)\n",
    "            axes[i].imshow(channel_image, cmap=\"gray\")\n",
    "            axes[i].set_title(f\"Channel {i}\")\n",
    "            # print(f\"Max value in channel {i}:\", np.max(channel_image))\n",
    "            # print(f\"Min value in channel {i}:\", np.min(channel_image))\n",
    "        plt.show()\n",
    "    \n",
    "    # Handle three-channel image (RGB)\n",
    "    elif channel_num == 3:\n",
    "        print(tensor_np.shape)\n",
    "        # Transpose from (channels, height, width) to (height, width, channels)\n",
    "        image_np = np.transpose(tensor_np, (height_index, width_index, channel_index))\n",
    "        plt.imshow(image_np)\n",
    "        plt.title(\"Three-channel image (RGB)\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_test_loader(model, test_loader, device, show_plot=False):\n",
    "    model.eval() \n",
    "    total_iou = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, mask in test_loader:\n",
    "            images = image.to(device)\n",
    "            masks = mask.to(device)  \n",
    "            \n",
    "            outputs = model(images)\n",
    "            total_iou += calculate_iou(predicted_mask, masks) \n",
    "            #  softmax\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "            #  predicted mask\n",
    "            predicted_mask = torch.argmax(probs, dim=1)  #dim=1 for batch predictions\n",
    "\n",
    "            # IoU for the current batch\n",
    "            \n",
    "            num_samples += 1\n",
    "\n",
    "            if show_plot:\n",
    "                display_tensor_as_image(images, 3, 1, 2, 3)\n",
    "                image_np = predicted_mask.squeeze().cpu().numpy()\n",
    "                plt.imshow(image_np, vmin=0, vmax=1, cmap='gray')\n",
    "                plt.axis('off')  \n",
    "                plt.show()\n",
    "\n",
    "    mean_iou = total_iou / len(test_loader)\n",
    "    print(f\"Mean IoU on the test set: {mean_iou:.4f}\")\n",
    "    \n",
    "    # mean IoU to wandb\n",
    "    # wandb.log({\"test_mean_iou\": mean_iou})\n",
    "    \n",
    "    return mean_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mmodel\u001b[49m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m Unet(n_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, variant\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconvtranspose\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "del model\n",
    "model = Unet(n_channels=3, n_classes=2, variant='convtranspose')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "load_checkpoint(model, optimizer, filename=\"var1_checkpoint.pth\")\n",
    "\n",
    "mean_iou = evaluate_model_on_test_loader(model, test_loader, device, show_plot=True)\n",
    "wandb.log({\"test_mean_iou\": mean_iou})\n",
    "wandb.finish()\n",
    "\"\"\" DELETING THE MODEL HERE TO FREE UP VRAM!!!!\n",
    " BUT ALSO so i dont have rename the model variable from the  previous block in later sections\"\"\"\n",
    "clear_gpu_memory(model, [train_loader, val_loader, test_loader])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vairant 2: Using `torch.nn.Upsample` for bilinear upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home-mscluster/remoosa/ComputerVisionLab/Lab3/wandb/run-20240920_225746-6i4hh26y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2322203-witwatersrand-university/Unet%20variant%202%20-%20bilinear%20upsampling/runs/6i4hh26y' target=\"_blank\">dark-resonance-4</a></strong> to <a href='https://wandb.ai/2322203-witwatersrand-university/Unet%20variant%202%20-%20bilinear%20upsampling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2322203-witwatersrand-university/Unet%20variant%202%20-%20bilinear%20upsampling' target=\"_blank\">https://wandb.ai/2322203-witwatersrand-university/Unet%20variant%202%20-%20bilinear%20upsampling</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2322203-witwatersrand-university/Unet%20variant%202%20-%20bilinear%20upsampling/runs/6i4hh26y' target=\"_blank\">https://wandb.ai/2322203-witwatersrand-university/Unet%20variant%202%20-%20bilinear%20upsampling/runs/6i4hh26y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found.\n",
      "Checkpoint saved at epoch 1\n",
      "Checkpoint saved at epoch 2\n",
      "Checkpoint saved at epoch 3\n",
      "Checkpoint saved at epoch 4\n",
      "Checkpoint saved at epoch 5\n",
      "Checkpoint saved at epoch 9\n",
      "Checkpoint saved at epoch 12\n",
      "Checkpoint saved at epoch 13\n",
      "Checkpoint saved at epoch 16\n",
      "Checkpoint saved at epoch 33\n",
      "Checkpoint saved at epoch 34\n",
      "Checkpoint saved at epoch 45\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wandb.init(project=\"Unet variant 2 - bilinear upsampling\")\n",
    "\n",
    "\n",
    "model = Unet(n_channels=3, n_classes=2,variant='upsampling')\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     model = model.to('cuda:1')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "#  checkpoints if any\n",
    "start_epoch = load_checkpoint(model, optimizer, filename=\"var2_checkpoint.pth\")\n",
    "\n",
    "num_epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    \n",
    "    # print(torch.cuda.memory_summary())\n",
    "\n",
    "    \n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "    train_iou = 0.0\n",
    "    \n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # outputs = outputs.float()\n",
    "        # outputs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "        # print(f\"Outputs min: {outputs.min()}, max: {outputs.max()}, shape: {outputs.shape}\")\n",
    "        # print(f\"Masks min: {masks.min()}, max: {masks.max()}, shape: {masks.shape}\")\n",
    "        \n",
    "        # BCE loss with logits \n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        #gradient clipping I dunno why we get nans\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        \n",
    "        #  loss and IoU\n",
    "        running_loss += loss.item()\n",
    "        train_iou += calculate_iou(outputs, masks)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_iou = train_iou/ len(train_loader)\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_iou = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            val_iou += calculate_iou(outputs, masks)\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_iou = val_iou /len(val_loader)\n",
    "\n",
    "\n",
    "    #  training and validation metrics to wandb\n",
    "    wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss, \"train_iou\": train_iou, \"val_iou\": val_iou})\n",
    "    \n",
    "    \n",
    "    # print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader)}\")\n",
    "    \n",
    "    # store model checkpoint if validation loss improves\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_checkpoint(model,optimizer, epoch, \"var2_checkpoint.pth\")\n",
    "        print(f\"Checkpoint saved at epoch {epoch + 1}\")\n",
    "\n",
    "    # model.cpu()\n",
    "    # del model\n",
    "    gc.collect() \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # print(torch.cuda.memory_summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the second base variant here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1736246/3703089074.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvar2_checkpoint.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m mean_iou \u001b[38;5;241m=\u001b[39m evaluate_model_on_test_loader(model, test_loader, device, show_plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_mean_iou\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_iou})\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[0;34m(model, optimizer, filename)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filename):\n\u001b[1;32m     18\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(filename)\n\u001b[0;32m---> 19\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     21\u001b[0m     epoch \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_state_dict'"
     ]
    }
   ],
   "source": [
    "test_dataset = PuzzleDataset(img_dir = \"./images-1024x768/test/\",\n",
    "                            mask_dir = \"./masks-1024x768/test/\")\n",
    "#since 10 images batches of 1 should be fine can do like batches of 2 i guess                        \n",
    "test_loader = DataLoader(test_dataset,batch_size =1, shuffle=True)\n",
    "\n",
    "\n",
    "del model\n",
    "model = Unet(n_channels=3, n_classes=2,variant='upsampling')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "load_checkpoint(model, optimizer, filename=\"var2_checkpoint.pth\")\n",
    "\n",
    "mean_iou = evaluate_model_on_test_loader(model, test_loader, device, show_plot=True)\n",
    "wandb.log({\"test_mean_iou\": mean_iou})\n",
    "wandb.finish()\n",
    "\"\"\" DELETING THE MODEL HERE TO FREE UP VRAM!!!!\n",
    " BUT ALSO so i dont have rename the model variable from the  previous block in later sections\"\"\"\n",
    "clear_gpu_memory(model, [train_loader, val_loader, test_loader])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "evaluate model on test set \n",
    "- accuracy\n",
    "- precision\n",
    "- recall\n",
    "- F1 score\n",
    "- IoU\n",
    "\n",
    "# Select the best model based on the validation IoU and report its performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asdasdasfafasd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Other architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U git+https://github.com/qubvel-org/segmentation_models.pytorch\n",
    "#!pip install lightning albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PuzzleDataset(\n",
    "    img_dir=\"./images-1024x768/train/\",\n",
    "    mask_dir=\"./masks-1024x768/train/\", \n",
    "    transform=True,\n",
    "    num_transforms=3,\n",
    "    include_inverse_mask=False \n",
    ")\n",
    "val_dataset = PuzzleDataset(\n",
    "    img_dir=\"./images-1024x768/val/\",\n",
    "    mask_dir=\"./masks-1024x768/val/\",\n",
    "    include_inverse_mask=False\n",
    ")\n",
    "\n",
    "test_dataset = PuzzleDataset(\n",
    "    img_dir = \"./images-1024x768/test/\",\n",
    "    mask_dir = \"./masks-1024x768/test/\",\n",
    "    include_inverse_mask=False\n",
    "\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=5,shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=5,shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "T_MAX = EPOCHS * len(train_dataloader)\n",
    "OUT_CLASSES = 1\n",
    "\n",
    "class UnetPlus(pl.LightningModule):\n",
    "    def __init__(self, arch, encoder_name, in_channels, out_classes, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = smp.create_model(\n",
    "            arch,\n",
    "            encoder_name=encoder_name,\n",
    "            in_channels=in_channels,\n",
    "            classes=out_classes,\n",
    "            **kwargs,\n",
    "        )\n",
    "        # preprocessing parameteres for image\n",
    "        params = smp.encoders.get_preprocessing_params(encoder_name)\n",
    "        self.register_buffer(\"std\", torch.tensor(params[\"std\"]).view(1, 3, 1, 1))\n",
    "        self.register_buffer(\"mean\", torch.tensor(params[\"mean\"]).view(1, 3, 1, 1))\n",
    "\n",
    "        # for image segmentation dice loss could be the best first choice\n",
    "        self.loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "\n",
    "        # initialize step metics\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "    def forward(self, image):\n",
    "        # normalize image here\n",
    "        image = (image - self.mean) / self.std\n",
    "        mask = self.model(image)\n",
    "        return mask\n",
    "\n",
    "    def shared_step(self, batch, stage):\n",
    "        #print(\"batch:\",batch[0].shape)\n",
    "        image, mask = batch\n",
    "        #image = batch[\"image\"]\n",
    "\n",
    "        # Shape of the image should be (batch_size, num_channels, height, width)\n",
    "        # if you work with grayscale images, expand channels dim to have [batch_size, 1, height, width]\n",
    "        assert image.ndim == 4\n",
    "\n",
    "        # Check that image dimensions are divisible by 32,\n",
    "        # encoder and decoder connected by `skip connections` and usually encoder have 5 stages of\n",
    "        # downsampling by factor 2 (2 ^ 5 = 32); e.g. if we have image with shape 65x65 we will have\n",
    "        # following shapes of features in encoder and decoder: 84, 42, 21, 10, 5 -> 5, 10, 20, 40, 80\n",
    "        # and we will get an error trying to concat these features\n",
    "        h, w = image.shape[2:]\n",
    "        assert h % 32 == 0 and w % 32 == 0\n",
    "\n",
    "        #mask = batch[\"mask\"]\n",
    "        assert mask.ndim == 4\n",
    "\n",
    "        # Check that mask values in between 0 and 1, NOT 0 and 255 for binary segmentation\n",
    "        assert mask.max() <= 1.0 and mask.min() >= 0\n",
    "\n",
    "        logits_mask = self.forward(image)\n",
    "        #print(f\"Logits mask shape: {logits_mask.shape}, Target mask shape: {mask.shape}\")\n",
    "\n",
    "\n",
    "        # Predicted mask contains logits, and loss_fn param `from_logits` is set to True\n",
    "        loss = self.loss_fn(logits_mask, mask)\n",
    "\n",
    "        # Lets compute metrics for some threshold\n",
    "        # first convert mask values to probabilities, then\n",
    "        # apply thresholding\n",
    "        prob_mask = logits_mask.sigmoid()\n",
    "        pred_mask = (prob_mask > 0.5).float()\n",
    "\n",
    "        # We will compute IoU metric by two ways\n",
    "        #   1. dataset-wise\n",
    "        #   2. image-wise\n",
    "        # but for now we just compute true positive, false positive, false negative and\n",
    "        # true negative 'pixels' for each image and class\n",
    "        # these values will be aggregated in the end of an epoch\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(\n",
    "            pred_mask.long(), mask.long(), mode=\"binary\"\n",
    "        )\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"tp\": tp,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn,\n",
    "            \"tn\": tn,\n",
    "        }\n",
    "\n",
    "    def shared_epoch_end(self, outputs, stage):\n",
    "        losses = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(f\"val_loss\", losses, prog_bar=True)\n",
    "        # aggregate step metics\n",
    "        tp = torch.cat([x[\"tp\"] for x in outputs])\n",
    "        fp = torch.cat([x[\"fp\"] for x in outputs])\n",
    "        fn = torch.cat([x[\"fn\"] for x in outputs])\n",
    "        tn = torch.cat([x[\"tn\"] for x in outputs])\n",
    "\n",
    "        #F1 score\n",
    "        precision = tp.sum() / (tp.sum() + fp.sum() + 1e-6)  # Add small value to avoid division by zero\n",
    "        recall = tp.sum() / (tp.sum() + fn.sum() + 1e-6)     # Add small value to avoid division by zero\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall + 1e-6)    \n",
    "        # per image IoU means that we first calculate IoU score for each image\n",
    "        # and then compute mean over these scores\n",
    "        per_image_iou = smp.metrics.iou_score(\n",
    "            tp, fp, fn, tn, reduction=\"micro-imagewise\"\n",
    "        )\n",
    "\n",
    "        # dataset IoU means that we aggregate intersection and union over whole dataset\n",
    "        # and then compute IoU score. The difference between dataset_iou and per_image_iou scores\n",
    "        # in this particular case will not be much, however for dataset\n",
    "        # with \"empty\" images (images without target class) a large gap could be observed.\n",
    "        # Empty images influence a lot on per_image_iou and much less on dataset_iou.\n",
    "        dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        metrics = {\n",
    "            f\"{stage}_per_image_iou\": per_image_iou,\n",
    "            f\"{stage}_dataset_iou\": dataset_iou,\n",
    "            f\"{stage}_f1_score\": f1_score  # Log the F1 score\n",
    "        }\n",
    "\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        train_loss_info = self.shared_step(batch, \"train\")\n",
    "        # append the metics of each step to the\n",
    "        self.training_step_outputs.append(train_loss_info)\n",
    "        return train_loss_info\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.shared_epoch_end(self.training_step_outputs, \"train\")\n",
    "        # empty set output list\n",
    "        self.training_step_outputs.clear()\n",
    "        return\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        valid_loss_info = self.shared_step(batch, \"valid\")\n",
    "        self.validation_step_outputs.append(valid_loss_info)\n",
    "        return valid_loss_info\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.shared_epoch_end(self.validation_step_outputs, \"valid\")\n",
    "        self.validation_step_outputs.clear()\n",
    "        return\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        test_loss_info = self.shared_step(batch, \"test\")\n",
    "        self.test_step_outputs.append(test_loss_info)\n",
    "        return test_loss_info\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.shared_epoch_end(self.test_step_outputs, \"test\")\n",
    "        # empty set output list\n",
    "        self.test_step_outputs.clear()\n",
    "        return\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-4)\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_MAX, eta_min=1e-5)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resnet 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnetRes = UnetPlus(\"Unet\",\"resnet34\",3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS,log_every_n_steps=1)\n",
    "\n",
    "trainer.fit(\n",
    "    UnetRes,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run validation dataset\n",
    "valid_metrics = trainer.validate(UnetRes, dataloaders=val_dataloader, verbose=False)\n",
    "print(valid_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run test dataset\n",
    "test_metrics = trainer.test(UnetRes, dataloaders=test_dataloader, verbose=False)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mean_iou = evaluate_model_on_test_loader(UnetRes, test_dataloader, device, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "smp_model = UnetRes.model\n",
    "\n",
    "commit_info = smp_model.save_pretrained(\n",
    "    save_directory=\"saved_models/UnetPlus/UnetRes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Unet VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnetVGG = UnetPlus(\"Unet\",\"vgg11\",3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS,log_every_n_steps=1)\n",
    "\n",
    "trainer.fit(\n",
    "    UnetVGG,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run validation dataset\n",
    "valid_metrics = trainer.validate(UnetVGG, dataloaders=val_dataloader, verbose=False)\n",
    "print(valid_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run test dataset\n",
    "test_metrics = trainer.test(UnetVGG, dataloaders=test_dataloader, verbose=False)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mean_iou = evaluate_model_on_test_loader(UnetVGG, test_dataloader, device, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "smp_model = UnetVGG.model\n",
    "\n",
    "commit_info = smp_model.save_pretrained(\n",
    "    save_directory=\"saved_models/UnetPlus/UnetVGG\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Unet Mobileone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UnetMobile = UnetPlus(\"Unet\",\"mobileone_s2\",3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS,log_every_n_steps=1)\n",
    "\n",
    "trainer.fit(\n",
    "    UnetMobile,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run validation dataset\n",
    "valid_metrics = trainer.validate(UnetMobile, dataloaders=val_dataloader, verbose=False)\n",
    "print(valid_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run test dataset\n",
    "test_metrics = trainer.test(UnetMobile, dataloaders=test_dataloader, verbose=False)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mean_iou = evaluate_model_on_test_loader(UnetVGG, test_dataloader, device, show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "smp_model = UnetMobile.model\n",
    "\n",
    "commit_info = smp_model.save_pretrained(\n",
    "    save_directory=\"saved_models/UnetPlus/UnetMobile\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLabV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep lab v3\n",
    "EPOCHS = 30\n",
    "T_MAX = EPOCHS * len(train_dataloader)\n",
    "OUT_CLASSES = 2\n",
    "\n",
    "class DeepV_plus(pl.LightningModule):\n",
    "    def __init__(self, arch, encoder_name, in_channels, out_classes, pretrained=\"imagenet\", **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = smp.create_model(\n",
    "            arch,\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=pretrained,\n",
    "            in_channels=in_channels,\n",
    "            classes=out_classes,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.encoder_name = encoder_name\n",
    "        self.arch_name = arch\n",
    "        self.in_channels = in_channels\n",
    "        self.out_classes = out_classes\n",
    "        # preprocessing parameteres for image\n",
    "        print(pretrained)\n",
    "        params = smp.encoders.get_preprocessing_params(encoder_name,pretrained)\n",
    "        self.register_buffer(\"std\", torch.tensor(params[\"std\"]).view(1, 3, 1, 1))\n",
    "        self.register_buffer(\"mean\", torch.tensor(params[\"mean\"]).view(1, 3, 1, 1))\n",
    "\n",
    "        # for image segmentation dice loss could be the best first choice\n",
    "        self.loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
    "\n",
    "        # initialize step metics\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "    def forward(self, image):\n",
    "        # normalize image here\n",
    "        image = (image - self.mean) / self.std\n",
    "        mask = self.model(image)\n",
    "        return mask\n",
    "\n",
    "    def shared_step(self, batch, stage):\n",
    "        image = batch[0]\n",
    "\n",
    "        # Shape of the image should be (batch_size, num_channels, height, width)\n",
    "        # if you work with grayscale images, expand channels dim to have [batch_size, 1, height, width]\n",
    "        assert image.ndim == 4\n",
    "\n",
    "        # Check that image dimensions are divisible by 32,\n",
    "        # encoder and decoder connected by `skip connections` and usually encoder have 5 stages of\n",
    "        # downsampling by factor 2 (2 ^ 5 = 32); e.g. if we have image with shape 65x65 we will have\n",
    "        # following shapes of features in encoder and decoder: 84, 42, 21, 10, 5 -> 5, 10, 20, 40, 80\n",
    "        # and we will get an error trying to concat these features\n",
    "        h, w = image.shape[2:]\n",
    "        assert h % 32 == 0 and w % 32 == 0\n",
    "\n",
    "        mask = batch[1]\n",
    "        assert mask.ndim == 4\n",
    "\n",
    "        # Check that mask values in between 0 and 1, NOT 0 and 255 for binary segmentation\n",
    "        assert mask.max() <= 1.0 and mask.min() >= 0\n",
    "\n",
    "        logits_mask = self.forward(image)\n",
    "\n",
    "        # Predicted mask contains logits, and loss_fn param `from_logits` is set to True\n",
    "        loss = self.loss_fn(logits_mask, mask)\n",
    "\n",
    "        # Lets compute metrics for some threshold\n",
    "        # first convert mask values to probabilities, then\n",
    "        # apply thresholding\n",
    "        prob_mask = logits_mask.sigmoid()\n",
    "        pred_mask = (prob_mask > 0.5).float()\n",
    "        # We will compute IoU metric by two ways\n",
    "        #   1. dataset-wise\n",
    "        #   2. image-wise\n",
    "        # but for now we just compute true positive, false positive, false negative and\n",
    "        # true negative 'pixels' for each image and class\n",
    "        # these values will be aggregated in the end of an epoch\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(\n",
    "            pred_mask.long(), mask.long(), mode=\"binary\"\n",
    "        )\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"tp\": tp,\n",
    "            \"fp\": fp,\n",
    "            \"fn\": fn,\n",
    "            \"tn\": tn,\n",
    "        }\n",
    "\n",
    "    def shared_epoch_end(self, outputs, stage):\n",
    "        \n",
    "        losses = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        self.log(f\"val_loss\", losses, prog_bar=True)\n",
    "        # aggregate step metics\n",
    "        tp = torch.cat([x[\"tp\"] for x in outputs])\n",
    "        fp = torch.cat([x[\"fp\"] for x in outputs])\n",
    "        fn = torch.cat([x[\"fn\"] for x in outputs])\n",
    "        tn = torch.cat([x[\"tn\"] for x in outputs])\n",
    "\n",
    "        #F1 score\n",
    "        precision = tp.sum() / (tp.sum() + fp.sum() + 1e-6)  # Add small value to avoid division by zero\n",
    "        recall = tp.sum() / (tp.sum() + fn.sum() + 1e-6)     # Add small value to avoid division by zero\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall + 1e-6)    \n",
    "        # per image IoU means that we first calculate IoU score for each image\n",
    "        # and then compute mean over these scores\n",
    "        per_image_iou = smp.metrics.iou_score(\n",
    "            tp, fp, fn, tn, reduction=\"micro-imagewise\"\n",
    "        )\n",
    "\n",
    "        # dataset IoU means that we aggregate intersection and union over whole dataset\n",
    "        # and then compute IoU score. The difference between dataset_iou and per_image_iou scores\n",
    "        # in this particular case will not be much, however for dataset\n",
    "        # with \"empty\" images (images without target class) a large gap could be observed.\n",
    "        # Empty images influence a lot on per_image_iou and much less on dataset_iou.\n",
    "        dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
    "        metrics = {\n",
    "            f\"{stage}_per_image_iou\": per_image_iou,\n",
    "            f\"{stage}_dataset_iou\": dataset_iou,\n",
    "            f\"{stage}_f1_score\": f1_score  # Log the F1 score\n",
    "        }\n",
    "\n",
    "        self.log_dict(metrics, prog_bar=True)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        train_loss_info = self.shared_step(batch, \"train\")\n",
    "        # append the metics of each step to the\n",
    "        self.training_step_outputs.append(train_loss_info)\n",
    "        return train_loss_info\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.shared_epoch_end(self.training_step_outputs, \"train\")\n",
    "        # empty set output list\n",
    "        self.training_step_outputs.clear()\n",
    "        return\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        valid_loss_info = self.shared_step(batch, \"valid\")\n",
    "        self.validation_step_outputs.append(valid_loss_info)\n",
    "        return valid_loss_info\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.shared_epoch_end(self.validation_step_outputs, \"valid\")\n",
    "        self.validation_step_outputs.clear()\n",
    "        return\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        test_loss_info = self.shared_step(batch, \"test\")\n",
    "        self.test_step_outputs.append(test_loss_info)\n",
    "        return test_loss_info\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.shared_epoch_end(self.test_step_outputs, \"test\")\n",
    "        # empty set output list\n",
    "        self.test_step_outputs.clear()\n",
    "        return\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=2e-4)\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_MAX, eta_min=1e-5)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "        return\n",
    "    def on_save_checkpoint(self, checkpoint):\n",
    "        # Save hyperparameters in the checkpoint\n",
    "        checkpoint['hyper_parameters'] = {\n",
    "            'arch': self.arch_name,\n",
    "            'encoder_name': self.encoder_name,\n",
    "            'in_channels': self.in_channels,  # Assuming model has this attribute\n",
    "            'out_classes': self.out_classes,  # Assuming model has this attribute\n",
    "        }\n",
    "    @classmethod\n",
    "    def load_from_checkpoint(cls, checkpoint_path, **kwargs):\n",
    "        \"\"\"\n",
    "        Load model weights from a checkpoint and instantiate the model.\n",
    "\n",
    "        Parameters:\n",
    "        checkpoint_path (str): Path to the checkpoint file.\n",
    "        kwargs (dict): Additional arguments to pass to the model initialization.\n",
    "\n",
    "        Returns:\n",
    "        DeepV_plus: Model instance with weights loaded from the checkpoint.\n",
    "        \"\"\"\n",
    "        # Load the checkpoint\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
    "        \n",
    "        # Get model parameters from the checkpoint\n",
    "        model_params = checkpoint['hyper_parameters']\n",
    "\n",
    "        # Create a new instance of the model using parameters from the checkpoint\n",
    "        model = cls(\n",
    "            arch=kwargs.get('arch', model_params['arch']),\n",
    "            encoder_name=kwargs.get('encoder_name', model_params['encoder_name']),\n",
    "            in_channels=kwargs.get('in_channels', model_params['in_channels']),\n",
    "            out_classes=kwargs.get('out_classes', model_params['out_classes']),\n",
    "        )\n",
    "        \n",
    "        # Load the state dictionary into the model\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import wandb\n",
    "\n",
    "def train_deep_model(deepvPlus:DeepV_plus):\n",
    "    wandb.finish()\n",
    "    # Initialize WandbLogger\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"DeeplabV3Plus\",  # Your Wandb project name\n",
    "        name=f\"{deepvPlus.arch_name}-{deepvPlus.encoder_name}\",   # Experiment name\n",
    "        log_model=True,  # Log model checkpoints to Wandb\n",
    "        reinit=True \n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"deepCheckpoints/\",  # Directory to save checkpoints\n",
    "        filename=f\"{deepvPlus.arch_name}-{deepvPlus.encoder_name}\",  # Naming convention for the checkpoints\n",
    "        monitor=\"val_loss\",  # Metric to monitor for checkpoint saving\n",
    "        save_top_k=1,  # Save top 1 models with the best 'val_loss'\n",
    "        mode=\"min\",  # Save models with minimum 'val_loss'\n",
    "        save_last=True,  # Also save the latest checkpoint\n",
    "        verbose=True,  # Verbosity of saving messages\n",
    "        enable_version_counter=False,\n",
    "    )\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=EPOCHS, \n",
    "        log_every_n_steps=1, \n",
    "        callbacks=[checkpoint_callback],  # Add the checkpoint callback here\n",
    "        logger=wandb_logger  # Attach the Wandb logger\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        deepvPlus,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "\n",
    "    valid_metrics = trainer.validate(deepvPlus, dataloaders=val_dataloader, verbose=False)\n",
    "    print(valid_metrics)\n",
    "\n",
    "    test_metrics = trainer.test(deepvPlus, dataloaders=test_dataloader, verbose=False)\n",
    "    print(test_metrics)\n",
    "\n",
    "    # smp_model = deepvPlus.model\n",
    "\n",
    "    # commit_info = smp_model.save_pretrained(\n",
    "    #     save_directory=\"saved_models/DeepLabv3Plus\",\n",
    "    # )\n",
    "\n",
    "    clear_gpu_memory(deepvPlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_name):\n",
    "    # Load the model from the checkpoint\n",
    "    trainer = pl.Trainer(max_epochs=1000)\n",
    "    deepvPlus = DeepV_plus.load_from_checkpoint(f\"deepCheckpoints/{checkpoint_name}.ckpt\")\n",
    "    \n",
    "    valid_metrics = trainer.validate(deepvPlus, dataloaders=val_dataloader, verbose=False)\n",
    "    print(valid_metrics)\n",
    "\n",
    "    test_metrics = trainer.test(deepvPlus, dataloaders=test_dataloader, verbose=False)\n",
    "    print(test_metrics)\n",
    "    clear_gpu_memory(deepvPlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m2180153\u001b[0m (\u001b[33m2180153-wits-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240921_125024-p7zspisu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34/runs/p7zspisu' target=\"_blank\">deeplabv3plus-resnet34</a></strong> to <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34/runs/p7zspisu' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34/runs/p7zspisu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Tumi\\Other Subjects\\CV\\ComputerVisionLab\\Lab3\\deepCheckpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type          | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model   | DeepLabV3Plus | 22.4 M | train\n",
      "1 | loss_fn | DiceLoss      | 0      | train\n",
      "--------------------------------------------------\n",
      "22.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.4 M    Total params\n",
      "89.751    Total estimated model params size (MB)\n",
      "173       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 20/20 [00:02<00:00, 10.00it/s, v_num=pisu, val_loss=0.346, valid_per_image_iou=0.781, valid_dataset_iou=0.780, valid_f1_score=0.877]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 20: 'val_loss' reached 0.31060 (best 0.31060), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 20/20 [00:01<00:00, 11.00it/s, v_num=pisu, val_loss=0.152, valid_per_image_iou=0.915, valid_dataset_iou=0.915, valid_f1_score=0.956, train_per_image_iou=0.754, train_dataset_iou=0.735, train_f1_score=0.847]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 40: 'val_loss' reached 0.16541 (best 0.16541), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 20/20 [00:01<00:00, 10.58it/s, v_num=pisu, val_loss=0.103, valid_per_image_iou=0.947, valid_dataset_iou=0.947, valid_f1_score=0.973, train_per_image_iou=0.872, train_dataset_iou=0.872, train_f1_score=0.932]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 60: 'val_loss' reached 0.12245 (best 0.12245), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 20/20 [00:01<00:00, 10.56it/s, v_num=pisu, val_loss=0.0845, valid_per_image_iou=0.963, valid_dataset_iou=0.963, valid_f1_score=0.981, train_per_image_iou=0.918, train_dataset_iou=0.918, train_f1_score=0.957]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 80: 'val_loss' reached 0.09736 (best 0.09736), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 20/20 [00:01<00:00, 10.28it/s, v_num=pisu, val_loss=0.0701, valid_per_image_iou=0.975, valid_dataset_iou=0.975, valid_f1_score=0.987, train_per_image_iou=0.940, train_dataset_iou=0.940, train_f1_score=0.969]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 100: 'val_loss' reached 0.07913 (best 0.07913), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 20/20 [00:01<00:00, 10.64it/s, v_num=pisu, val_loss=0.0625, valid_per_image_iou=0.968, valid_dataset_iou=0.968, valid_f1_score=0.984, train_per_image_iou=0.955, train_dataset_iou=0.955, train_f1_score=0.977]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 120: 'val_loss' reached 0.06596 (best 0.06596), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 20/20 [00:01<00:00, 10.61it/s, v_num=pisu, val_loss=0.0526, valid_per_image_iou=0.979, valid_dataset_iou=0.979, valid_f1_score=0.989, train_per_image_iou=0.966, train_dataset_iou=0.966, train_f1_score=0.983]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 140: 'val_loss' reached 0.05587 (best 0.05587), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 20/20 [00:01<00:00, 10.68it/s, v_num=pisu, val_loss=0.0453, valid_per_image_iou=0.982, valid_dataset_iou=0.982, valid_f1_score=0.991, train_per_image_iou=0.972, train_dataset_iou=0.972, train_f1_score=0.986]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 160: 'val_loss' reached 0.04787 (best 0.04787), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 20/20 [00:01<00:00, 10.40it/s, v_num=pisu, val_loss=0.0422, valid_per_image_iou=0.984, valid_dataset_iou=0.984, valid_f1_score=0.992, train_per_image_iou=0.977, train_dataset_iou=0.977, train_f1_score=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 180: 'val_loss' reached 0.04189 (best 0.04189), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 20/20 [00:01<00:00, 10.53it/s, v_num=pisu, val_loss=0.0369, valid_per_image_iou=0.984, valid_dataset_iou=0.984, valid_f1_score=0.992, train_per_image_iou=0.980, train_dataset_iou=0.980, train_f1_score=0.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 200: 'val_loss' reached 0.03687 (best 0.03687), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 20/20 [00:01<00:00, 10.51it/s, v_num=pisu, val_loss=0.0321, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.993, train_per_image_iou=0.983, train_dataset_iou=0.983, train_f1_score=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 220: 'val_loss' reached 0.03295 (best 0.03295), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 20/20 [00:01<00:00, 10.58it/s, v_num=pisu, val_loss=0.0295, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.984, train_dataset_iou=0.984, train_f1_score=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 240: 'val_loss' reached 0.02971 (best 0.02971), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, v_num=pisu, val_loss=0.0284, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.986, train_dataset_iou=0.986, train_f1_score=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 260: 'val_loss' reached 0.02725 (best 0.02725), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 20/20 [00:01<00:00, 10.47it/s, v_num=pisu, val_loss=0.0246, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.987, train_dataset_iou=0.987, train_f1_score=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 280: 'val_loss' reached 0.02519 (best 0.02519), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 20/20 [00:01<00:00, 10.64it/s, v_num=pisu, val_loss=0.0243, valid_per_image_iou=0.989, valid_dataset_iou=0.989, valid_f1_score=0.994, train_per_image_iou=0.987, train_dataset_iou=0.987, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 300: 'val_loss' reached 0.02341 (best 0.02341), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 20/20 [00:01<00:00, 10.55it/s, v_num=pisu, val_loss=0.0226, valid_per_image_iou=0.989, valid_dataset_iou=0.989, valid_f1_score=0.994, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 320: 'val_loss' reached 0.02201 (best 0.02201), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 20/20 [00:01<00:00, 10.69it/s, v_num=pisu, val_loss=0.0219, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 340: 'val_loss' reached 0.02076 (best 0.02076), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, v_num=pisu, val_loss=0.0205, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 360: 'val_loss' reached 0.01978 (best 0.01978), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, v_num=pisu, val_loss=0.0196, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 380: 'val_loss' reached 0.01906 (best 0.01906), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 20/20 [00:01<00:00, 10.75it/s, v_num=pisu, val_loss=0.0191, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 400: 'val_loss' reached 0.01852 (best 0.01852), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 20/20 [00:01<00:00, 10.38it/s, v_num=pisu, val_loss=0.0182, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 420: 'val_loss' reached 0.01785 (best 0.01785), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 20/20 [00:01<00:00, 10.48it/s, v_num=pisu, val_loss=0.0181, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 440: 'val_loss' reached 0.01745 (best 0.01745), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 20/20 [00:01<00:00, 10.52it/s, v_num=pisu, val_loss=0.0175, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 460: 'val_loss' reached 0.01708 (best 0.01708), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 20/20 [00:01<00:00, 10.24it/s, v_num=pisu, val_loss=0.0168, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 480: 'val_loss' reached 0.01677 (best 0.01677), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 20/20 [00:01<00:00, 10.08it/s, v_num=pisu, val_loss=0.0172, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 500: 'val_loss' reached 0.01638 (best 0.01638), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 20/20 [00:01<00:00, 10.36it/s, v_num=pisu, val_loss=0.0168, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 520: 'val_loss' reached 0.01633 (best 0.01633), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 20/20 [00:01<00:00, 10.45it/s, v_num=pisu, val_loss=0.0171, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 540: 'val_loss' reached 0.01613 (best 0.01613), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 20/20 [00:01<00:00, 10.29it/s, v_num=pisu, val_loss=0.0162, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 560: 'val_loss' reached 0.01607 (best 0.01607), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 20/20 [00:01<00:00, 10.62it/s, v_num=pisu, val_loss=0.0163, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 580: 'val_loss' reached 0.01587 (best 0.01587), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:01<00:00, 10.42it/s, v_num=pisu, val_loss=0.0162, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 600: 'val_loss' reached 0.01584 (best 0.01584), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnet34.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:05<00:00,  3.94it/s, v_num=pisu, val_loss=0.0162, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  9.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'val_loss': 0.016173720359802246, 'valid_per_image_iou': 0.9909735321998596, 'valid_dataset_iou': 0.9909728169441223, 'valid_f1_score': 0.9954655170440674}]\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 44.01it/s]\n",
      "[{'val_loss': 0.01553952693939209, 'test_per_image_iou': 0.9910772442817688, 'test_dataset_iou': 0.9910755753517151, 'test_f1_score': 0.9955173134803772}]\n"
     ]
    }
   ],
   "source": [
    "deepvPlus_model = DeepV_plus(\"deeplabv3plus\", \"resnet34\", in_channels=3, out_classes=2)\n",
    "train_deep_model(deepvPlus_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>test_dataset_iou</td><td>▁</td></tr><tr><td>test_f1_score</td><td>▁</td></tr><tr><td>test_per_image_iou</td><td>▁</td></tr><tr><td>train_dataset_iou</td><td>▁▅▆▇▇▇▇███████████████████████</td></tr><tr><td>train_f1_score</td><td>▁▅▆▇▇▇████████████████████████</td></tr><tr><td>train_per_image_iou</td><td>▁▅▆▇▇▇▇███████████████████████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▇▄▃▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_dataset_iou</td><td>▁▅▇▇▇▇█████████████████████████</td></tr><tr><td>valid_f1_score</td><td>▁▆▇▇█▇█████████████████████████</td></tr><tr><td>valid_per_image_iou</td><td>▁▅▇▇▇▇█████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>test_dataset_iou</td><td>0.99108</td></tr><tr><td>test_f1_score</td><td>0.99552</td></tr><tr><td>test_per_image_iou</td><td>0.99108</td></tr><tr><td>train_dataset_iou</td><td>0.99052</td></tr><tr><td>train_f1_score</td><td>0.99524</td></tr><tr><td>train_per_image_iou</td><td>0.99052</td></tr><tr><td>trainer/global_step</td><td>600</td></tr><tr><td>val_loss</td><td>0.01554</td></tr><tr><td>valid_dataset_iou</td><td>0.99097</td></tr><tr><td>valid_f1_score</td><td>0.99547</td></tr><tr><td>valid_per_image_iou</td><td>0.99097</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deeplabv3plus-resnet34</strong> at: <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34/runs/p7zspisu' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34/runs/p7zspisu</a><br/> View project at: <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnet34</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240921_125024-p7zspisu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240921_125320-vfdzhdac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d/runs/vfdzhdac' target=\"_blank\">deeplabv3plus-resnext50_32x4d</a></strong> to <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d/runs/vfdzhdac' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d/runs/vfdzhdac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Tumi\\Other Subjects\\CV\\ComputerVisionLab\\Lab3\\deepCheckpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type          | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model   | DeepLabV3Plus | 26.1 M | train\n",
      "1 | loss_fn | DiceLoss      | 0      | train\n",
      "--------------------------------------------------\n",
      "26.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.1 M    Total params\n",
      "104.599   Total estimated model params size (MB)\n",
      "208       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 20/20 [00:03<00:00,  6.25it/s, v_num=hdac, val_loss=0.342, valid_per_image_iou=0.805, valid_dataset_iou=0.805, valid_f1_score=0.892]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 20: 'val_loss' reached 0.29444 (best 0.29444), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 20/20 [00:03<00:00,  6.04it/s, v_num=hdac, val_loss=0.163, valid_per_image_iou=0.876, valid_dataset_iou=0.876, valid_f1_score=0.934, train_per_image_iou=0.771, train_dataset_iou=0.761, train_f1_score=0.865]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 40: 'val_loss' reached 0.16729 (best 0.16729), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 20/20 [00:03<00:00,  5.97it/s, v_num=hdac, val_loss=0.106, valid_per_image_iou=0.957, valid_dataset_iou=0.957, valid_f1_score=0.978, train_per_image_iou=0.853, train_dataset_iou=0.853, train_f1_score=0.920]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 60: 'val_loss' reached 0.12167 (best 0.12167), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 20/20 [00:03<00:00,  5.98it/s, v_num=hdac, val_loss=0.0836, valid_per_image_iou=0.966, valid_dataset_iou=0.966, valid_f1_score=0.983, train_per_image_iou=0.913, train_dataset_iou=0.912, train_f1_score=0.954]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 80: 'val_loss' reached 0.09370 (best 0.09370), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 20/20 [00:03<00:00,  6.00it/s, v_num=hdac, val_loss=0.0638, valid_per_image_iou=0.974, valid_dataset_iou=0.974, valid_f1_score=0.987, train_per_image_iou=0.945, train_dataset_iou=0.945, train_f1_score=0.972]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 100: 'val_loss' reached 0.07444 (best 0.07444), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 20/20 [00:03<00:00,  5.80it/s, v_num=hdac, val_loss=0.0565, valid_per_image_iou=0.978, valid_dataset_iou=0.978, valid_f1_score=0.989, train_per_image_iou=0.963, train_dataset_iou=0.963, train_f1_score=0.981]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 120: 'val_loss' reached 0.06117 (best 0.06117), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 20/20 [00:03<00:00,  5.88it/s, v_num=hdac, val_loss=0.0474, valid_per_image_iou=0.983, valid_dataset_iou=0.983, valid_f1_score=0.991, train_per_image_iou=0.970, train_dataset_iou=0.970, train_f1_score=0.985]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 140: 'val_loss' reached 0.05071 (best 0.05071), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 20/20 [00:03<00:00,  6.00it/s, v_num=hdac, val_loss=0.0397, valid_per_image_iou=0.985, valid_dataset_iou=0.985, valid_f1_score=0.993, train_per_image_iou=0.977, train_dataset_iou=0.977, train_f1_score=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 160: 'val_loss' reached 0.04263 (best 0.04263), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s, v_num=hdac, val_loss=0.0346, valid_per_image_iou=0.986, valid_dataset_iou=0.986, valid_f1_score=0.993, train_per_image_iou=0.982, train_dataset_iou=0.982, train_f1_score=0.991]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 180: 'val_loss' reached 0.03667 (best 0.03667), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 20/20 [00:03<00:00,  5.92it/s, v_num=hdac, val_loss=0.0312, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.984, train_dataset_iou=0.984, train_f1_score=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 200: 'val_loss' reached 0.03228 (best 0.03228), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 20/20 [00:03<00:00,  5.94it/s, v_num=hdac, val_loss=0.0278, valid_per_image_iou=0.989, valid_dataset_iou=0.989, valid_f1_score=0.994, train_per_image_iou=0.986, train_dataset_iou=0.986, train_f1_score=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 220: 'val_loss' reached 0.02870 (best 0.02870), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 20/20 [00:03<00:00,  5.89it/s, v_num=hdac, val_loss=0.0252, valid_per_image_iou=0.989, valid_dataset_iou=0.989, valid_f1_score=0.995, train_per_image_iou=0.987, train_dataset_iou=0.987, train_f1_score=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 240: 'val_loss' reached 0.02603 (best 0.02603), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 20/20 [00:03<00:00,  5.92it/s, v_num=hdac, val_loss=0.0235, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 260: 'val_loss' reached 0.02390 (best 0.02390), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 20/20 [00:03<00:00,  5.92it/s, v_num=hdac, val_loss=0.0203, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 280: 'val_loss' reached 0.02212 (best 0.02212), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 20/20 [00:03<00:00,  5.84it/s, v_num=hdac, val_loss=0.0201, valid_per_image_iou=0.990, valid_dataset_iou=0.990, valid_f1_score=0.995, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 300: 'val_loss' reached 0.02053 (best 0.02053), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 20/20 [00:03<00:00,  5.79it/s, v_num=hdac, val_loss=0.0188, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.995, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 320: 'val_loss' reached 0.01934 (best 0.01934), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 20/20 [00:03<00:00,  5.77it/s, v_num=hdac, val_loss=0.0184, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.996, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 340: 'val_loss' reached 0.01840 (best 0.01840), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s, v_num=hdac, val_loss=0.0176, valid_per_image_iou=0.991, valid_dataset_iou=0.991, valid_f1_score=0.996, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 360: 'val_loss' reached 0.01759 (best 0.01759), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s, v_num=hdac, val_loss=0.0163, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.990, train_dataset_iou=0.990, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 380: 'val_loss' reached 0.01685 (best 0.01685), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 20/20 [00:03<00:00,  5.90it/s, v_num=hdac, val_loss=0.0162, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 400: 'val_loss' reached 0.01636 (best 0.01636), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 20/20 [00:03<00:00,  6.00it/s, v_num=hdac, val_loss=0.0157, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 420: 'val_loss' reached 0.01581 (best 0.01581), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 20/20 [00:03<00:00,  5.91it/s, v_num=hdac, val_loss=0.016, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 440: 'val_loss' reached 0.01552 (best 0.01552), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 20/20 [00:03<00:00,  5.80it/s, v_num=hdac, val_loss=0.0152, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 460: 'val_loss' reached 0.01516 (best 0.01516), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 20/20 [00:03<00:00,  5.99it/s, v_num=hdac, val_loss=0.0151, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 480: 'val_loss' reached 0.01487 (best 0.01487), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 20/20 [00:03<00:00,  5.87it/s, v_num=hdac, val_loss=0.015, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 500: 'val_loss' reached 0.01472 (best 0.01472), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 20/20 [00:03<00:00,  5.75it/s, v_num=hdac, val_loss=0.0149, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 520: 'val_loss' reached 0.01449 (best 0.01449), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 20/20 [00:03<00:00,  5.92it/s, v_num=hdac, val_loss=0.0144, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 540: 'val_loss' reached 0.01449 (best 0.01449), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 20/20 [00:03<00:00,  5.98it/s, v_num=hdac, val_loss=0.0142, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 560: 'val_loss' reached 0.01428 (best 0.01428), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 20/20 [00:03<00:00,  5.97it/s, v_num=hdac, val_loss=0.0144, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 580: 'val_loss' reached 0.01420 (best 0.01420), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:03<00:00,  5.93it/s, v_num=hdac, val_loss=0.0145, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 600: 'val_loss' reached 0.01411 (best 0.01411), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-resnext50_32x4d.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:06<00:00,  3.31it/s, v_num=hdac, val_loss=0.0145, valid_per_image_iou=0.992, valid_dataset_iou=0.992, valid_f1_score=0.996, train_per_image_iou=0.991, train_dataset_iou=0.991, train_f1_score=0.996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'val_loss': 0.014513224363327026, 'valid_per_image_iou': 0.9921114444732666, 'valid_dataset_iou': 0.9921113848686218, 'valid_f1_score': 0.996039628982544}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 31.21it/s]\n",
      "[{'val_loss': 0.013683512806892395, 'test_per_image_iou': 0.9918500185012817, 'test_dataset_iou': 0.9918493032455444, 'test_f1_score': 0.9959075450897217}]\n"
     ]
    }
   ],
   "source": [
    "deepvPlus_model = DeepV_plus(\"deeplabv3plus\", \"resnext50_32x4d\", in_channels=3, out_classes=2)\n",
    "train_deep_model(deepvPlus_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>test_dataset_iou</td><td>▁</td></tr><tr><td>test_f1_score</td><td>▁</td></tr><tr><td>test_per_image_iou</td><td>▁</td></tr><tr><td>train_dataset_iou</td><td>▁▄▆▇▇▇████████████████████████</td></tr><tr><td>train_f1_score</td><td>▁▄▆▇▇▇████████████████████████</td></tr><tr><td>train_per_image_iou</td><td>▁▄▆▇▇▇████████████████████████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▇▄▃▂▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_dataset_iou</td><td>▁▄▇▇▇▇█████████████████████████</td></tr><tr><td>valid_f1_score</td><td>▁▄▇▇▇██████████████████████████</td></tr><tr><td>valid_per_image_iou</td><td>▁▄▇▇▇▇█████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>test_dataset_iou</td><td>0.99185</td></tr><tr><td>test_f1_score</td><td>0.99591</td></tr><tr><td>test_per_image_iou</td><td>0.99185</td></tr><tr><td>train_dataset_iou</td><td>0.99138</td></tr><tr><td>train_f1_score</td><td>0.99567</td></tr><tr><td>train_per_image_iou</td><td>0.99138</td></tr><tr><td>trainer/global_step</td><td>600</td></tr><tr><td>val_loss</td><td>0.01368</td></tr><tr><td>valid_dataset_iou</td><td>0.99211</td></tr><tr><td>valid_f1_score</td><td>0.99604</td></tr><tr><td>valid_per_image_iou</td><td>0.99211</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deeplabv3plus-resnext50_32x4d</strong> at: <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d/runs/vfdzhdac' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d/runs/vfdzhdac</a><br/> View project at: <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-resnext50_32x4d</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240921_125320-vfdzhdac\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>.\\wandb\\run-20240921_125706-23fxqho7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032/runs/23fxqho7' target=\"_blank\">deeplabv3plus-timm-regnetx_032</a></strong> to <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032/runs/23fxqho7' target=\"_blank\">https://wandb.ai/2180153-wits-university/deeplabv3plus-timm-regnetx_032/runs/23fxqho7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\Tumi\\Other Subjects\\CV\\ComputerVisionLab\\Lab3\\deepCheckpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type          | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | model   | DeepLabV3Plus | 16.1 M | train\n",
      "1 | loss_fn | DiceLoss      | 0      | train\n",
      "--------------------------------------------------\n",
      "16.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.1 M    Total params\n",
      "64.362    Total estimated model params size (MB)\n",
      "586       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 20/20 [00:04<00:00,  4.86it/s, v_num=qho7, val_loss=0.366, valid_per_image_iou=0.746, valid_dataset_iou=0.746, valid_f1_score=0.854]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 20: 'val_loss' reached 0.31195 (best 0.31195), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 20/20 [00:04<00:00,  4.89it/s, v_num=qho7, val_loss=0.168, valid_per_image_iou=0.870, valid_dataset_iou=0.870, valid_f1_score=0.930, train_per_image_iou=0.743, train_dataset_iou=0.729, train_f1_score=0.843]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 40: 'val_loss' reached 0.16316 (best 0.16316), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 20/20 [00:04<00:00,  4.87it/s, v_num=qho7, val_loss=0.112, valid_per_image_iou=0.923, valid_dataset_iou=0.923, valid_f1_score=0.960, train_per_image_iou=0.861, train_dataset_iou=0.861, train_f1_score=0.925]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 60: 'val_loss' reached 0.12036 (best 0.12036), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 20/20 [00:03<00:00,  5.03it/s, v_num=qho7, val_loss=0.0857, valid_per_image_iou=0.955, valid_dataset_iou=0.955, valid_f1_score=0.977, train_per_image_iou=0.905, train_dataset_iou=0.905, train_f1_score=0.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 80: 'val_loss' reached 0.09387 (best 0.09387), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 20/20 [00:03<00:00,  5.02it/s, v_num=qho7, val_loss=0.0677, valid_per_image_iou=0.972, valid_dataset_iou=0.972, valid_f1_score=0.986, train_per_image_iou=0.933, train_dataset_iou=0.933, train_f1_score=0.966]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 100: 'val_loss' reached 0.07396 (best 0.07396), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 20/20 [00:04<00:00,  4.83it/s, v_num=qho7, val_loss=0.0544, valid_per_image_iou=0.976, valid_dataset_iou=0.976, valid_f1_score=0.988, train_per_image_iou=0.954, train_dataset_iou=0.954, train_f1_score=0.977]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 120: 'val_loss' reached 0.05972 (best 0.05972), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 20/20 [00:04<00:00,  4.82it/s, v_num=qho7, val_loss=0.048, valid_per_image_iou=0.978, valid_dataset_iou=0.978, valid_f1_score=0.989, train_per_image_iou=0.966, train_dataset_iou=0.966, train_f1_score=0.982] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 140: 'val_loss' reached 0.04962 (best 0.04962), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 20/20 [00:04<00:00,  4.78it/s, v_num=qho7, val_loss=0.0405, valid_per_image_iou=0.981, valid_dataset_iou=0.981, valid_f1_score=0.990, train_per_image_iou=0.974, train_dataset_iou=0.974, train_f1_score=0.987]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 160: 'val_loss' reached 0.04230 (best 0.04230), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 20/20 [00:04<00:00,  4.65it/s, v_num=qho7, val_loss=0.0351, valid_per_image_iou=0.983, valid_dataset_iou=0.983, valid_f1_score=0.991, train_per_image_iou=0.977, train_dataset_iou=0.977, train_f1_score=0.988]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 180: 'val_loss' reached 0.03693 (best 0.03693), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 20/20 [00:04<00:00,  4.95it/s, v_num=qho7, val_loss=0.0325, valid_per_image_iou=0.983, valid_dataset_iou=0.983, valid_f1_score=0.991, train_per_image_iou=0.980, train_dataset_iou=0.980, train_f1_score=0.990]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 200: 'val_loss' reached 0.03274 (best 0.03274), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 20/20 [00:04<00:00,  4.64it/s, v_num=qho7, val_loss=0.0296, valid_per_image_iou=0.985, valid_dataset_iou=0.985, valid_f1_score=0.992, train_per_image_iou=0.981, train_dataset_iou=0.981, train_f1_score=0.991]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 220: 'val_loss' reached 0.02951 (best 0.02951), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 20/20 [00:04<00:00,  4.79it/s, v_num=qho7, val_loss=0.0266, valid_per_image_iou=0.985, valid_dataset_iou=0.985, valid_f1_score=0.993, train_per_image_iou=0.983, train_dataset_iou=0.983, train_f1_score=0.991]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 240: 'val_loss' reached 0.02687 (best 0.02687), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 20/20 [00:04<00:00,  4.69it/s, v_num=qho7, val_loss=0.0246, valid_per_image_iou=0.986, valid_dataset_iou=0.986, valid_f1_score=0.993, train_per_image_iou=0.984, train_dataset_iou=0.984, train_f1_score=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 260: 'val_loss' reached 0.02480 (best 0.02480), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 20/20 [00:04<00:00,  4.86it/s, v_num=qho7, val_loss=0.0236, valid_per_image_iou=0.985, valid_dataset_iou=0.985, valid_f1_score=0.992, train_per_image_iou=0.985, train_dataset_iou=0.985, train_f1_score=0.992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 280: 'val_loss' reached 0.02299 (best 0.02299), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 20/20 [00:04<00:00,  4.97it/s, v_num=qho7, val_loss=0.022, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.993, train_per_image_iou=0.986, train_dataset_iou=0.986, train_f1_score=0.993] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 300: 'val_loss' reached 0.02161 (best 0.02161), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 20/20 [00:04<00:00,  4.99it/s, v_num=qho7, val_loss=0.0209, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.993, train_per_image_iou=0.986, train_dataset_iou=0.986, train_f1_score=0.993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 320: 'val_loss' reached 0.02031 (best 0.02031), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 20/20 [00:04<00:00,  4.99it/s, v_num=qho7, val_loss=0.0199, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.993, train_per_image_iou=0.987, train_dataset_iou=0.987, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 340: 'val_loss' reached 0.01927 (best 0.01927), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 20/20 [00:04<00:00,  4.98it/s, v_num=qho7, val_loss=0.0193, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.994, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 360: 'val_loss' reached 0.01852 (best 0.01852), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 20/20 [00:04<00:00,  4.86it/s, v_num=qho7, val_loss=0.0188, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.994, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 380: 'val_loss' reached 0.01782 (best 0.01782), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 20/20 [00:04<00:00,  4.97it/s, v_num=qho7, val_loss=0.0184, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.994, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 400: 'val_loss' reached 0.01718 (best 0.01718), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 20/20 [00:04<00:00,  4.92it/s, v_num=qho7, val_loss=0.0185, valid_per_image_iou=0.987, valid_dataset_iou=0.987, valid_f1_score=0.993, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 420: 'val_loss' reached 0.01683 (best 0.01683), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 20/20 [00:04<00:00,  4.90it/s, v_num=qho7, val_loss=0.0175, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.988, train_dataset_iou=0.988, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 440: 'val_loss' reached 0.01625 (best 0.01625), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 20/20 [00:04<00:00,  4.78it/s, v_num=qho7, val_loss=0.0171, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 460: 'val_loss' reached 0.01602 (best 0.01602), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 20/20 [00:04<00:00,  4.97it/s, v_num=qho7, val_loss=0.0169, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 480: 'val_loss' reached 0.01571 (best 0.01571), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 20/20 [00:04<00:00,  4.89it/s, v_num=qho7, val_loss=0.017, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 500: 'val_loss' reached 0.01548 (best 0.01548), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 20/20 [00:04<00:00,  4.94it/s, v_num=qho7, val_loss=0.0167, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 520: 'val_loss' reached 0.01537 (best 0.01537), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 20/20 [00:04<00:00,  4.91it/s, v_num=qho7, val_loss=0.0167, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 540: 'val_loss' reached 0.01526 (best 0.01526), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 20/20 [00:04<00:00,  4.94it/s, v_num=qho7, val_loss=0.0164, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 560: 'val_loss' reached 0.01508 (best 0.01508), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 20/20 [00:04<00:00,  4.89it/s, v_num=qho7, val_loss=0.016, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 580: 'val_loss' reached 0.01503 (best 0.01503), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:04<00:00,  4.81it/s, v_num=qho7, val_loss=0.0166, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 600: 'val_loss' reached 0.01489 (best 0.01489), saving model to 'C:\\\\Tumi\\\\Other Subjects\\\\CV\\\\ComputerVisionLab\\\\Lab3\\\\deepCheckpoints\\\\deeplabv3plus-timm-regnetx_032.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 20/20 [00:06<00:00,  3.27it/s, v_num=qho7, val_loss=0.0166, valid_per_image_iou=0.988, valid_dataset_iou=0.988, valid_f1_score=0.994, train_per_image_iou=0.989, train_dataset_iou=0.989, train_f1_score=0.995]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00,  9.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:475: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'val_loss': 0.016593188047409058, 'valid_per_image_iou': 0.9882156252861023, 'valid_dataset_iou': 0.9882150292396545, 'valid_f1_score': 0.9940721392631531}]\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 32.63it/s]\n",
      "[{'val_loss': 0.014644607901573181, 'test_per_image_iou': 0.9886478185653687, 'test_dataset_iou': 0.9886442422866821, 'test_f1_score': 0.994289219379425}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "deepvPlus_model = DeepV_plus(\"deeplabv3plus\", \"timm-regnetx_032\", in_channels=3, out_classes=2)\n",
    "train_deep_model(deepvPlus_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_38572\\3189538887.py:189: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 37.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[{'val_loss': 0.016173720359802246, 'valid_per_image_iou': 0.9909735321998596, 'valid_dataset_iou': 0.9909728169441223, 'valid_f1_score': 0.9954655170440674}]\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 53.99it/s] \n",
      "[{'val_loss': 0.01553952693939209, 'test_per_image_iou': 0.9910772442817688, 'test_dataset_iou': 0.9910755753517151, 'test_f1_score': 0.9955173134803772}]\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint(\"deeplabv3plus-resnet34\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
